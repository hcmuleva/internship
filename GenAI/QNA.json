{
  "data": {
    "edges": [
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "TextInput",
            "id": "TextInput-ZM95Q",
            "name": "text",
            "output_types": [
              "Message"
            ]
          // "Message" hello

          },
          "targetHandle": {
            "fieldName": "age",
            "id": "Prompt Template-iiNjI",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "xy-edge__TextInput-ZM95Q{œdataTypeœ:œTextInputœ,œidœ:œTextInput-ZM95Qœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-Prompt Template-iiNjI{œfieldNameœ:œageœ,œidœ:œPrompt Template-iiNjIœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "TextInput-ZM95Q",
        "sourceHandle": "{œdataTypeœ:œTextInputœ,œidœ:œTextInput-ZM95Qœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}",
        "target": "Prompt Template-iiNjI",
        "targetHandle": "{œfieldNameœ:œageœ,œidœ:œPrompt Template-iiNjIœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "TextInput",
            "id": "TextInput-zHjdu",
            "name": "text",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "level",
            "id": "Prompt Template-iiNjI",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "xy-edge__TextInput-zHjdu{œdataTypeœ:œTextInputœ,œidœ:œTextInput-zHjduœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-Prompt Template-iiNjI{œfieldNameœ:œlevelœ,œidœ:œPrompt Template-iiNjIœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "TextInput-zHjdu",
        "sourceHandle": "{œdataTypeœ:œTextInputœ,œidœ:œTextInput-zHjduœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}",
        "target": "Prompt Template-iiNjI",
        "targetHandle": "{œfieldNameœ:œlevelœ,œidœ:œPrompt Template-iiNjIœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "TextInput",
            "id": "TextInput-p6OwG",
            "name": "text",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "question",
            "id": "Prompt Template-iiNjI",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "xy-edge__TextInput-p6OwG{œdataTypeœ:œTextInputœ,œidœ:œTextInput-p6OwGœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-Prompt Template-iiNjI{œfieldNameœ:œquestionœ,œidœ:œPrompt Template-iiNjIœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "TextInput-p6OwG",
        "sourceHandle": "{œdataTypeœ:œTextInputœ,œidœ:œTextInput-p6OwGœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}",
        "target": "Prompt Template-iiNjI",
        "targetHandle": "{œfieldNameœ:œquestionœ,œidœ:œPrompt Template-iiNjIœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "TextInput",
            "id": "TextInput-YAms8",
            "name": "text",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "experience",
            "id": "Prompt Template-iiNjI",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "xy-edge__TextInput-YAms8{œdataTypeœ:œTextInputœ,œidœ:œTextInput-YAms8œ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-Prompt Template-iiNjI{œfieldNameœ:œexperienceœ,œidœ:œPrompt Template-iiNjIœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "TextInput-YAms8",
        "sourceHandle": "{œdataTypeœ:œTextInputœ,œidœ:œTextInput-YAms8œ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}",
        "target": "Prompt Template-iiNjI",
        "targetHandle": "{œfieldNameœ:œexperienceœ,œidœ:œPrompt Template-iiNjIœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "Prompt Template",
            "id": "Prompt Template-iiNjI",
            "name": "prompt",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "input_value",
            "id": "LanguageModelComponent-9qPkX",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "xy-edge__Prompt Template-iiNjI{œdataTypeœ:œPrompt Templateœ,œidœ:œPrompt Template-iiNjIœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}-LanguageModelComponent-9qPkX{œfieldNameœ:œinput_valueœ,œidœ:œLanguageModelComponent-9qPkXœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "Prompt Template-iiNjI",
        "sourceHandle": "{œdataTypeœ:œPrompt Templateœ,œidœ:œPrompt Template-iiNjIœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}",
        "target": "LanguageModelComponent-9qPkX",
        "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œLanguageModelComponent-9qPkXœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "TextInput",
            "id": "TextInput-G1fZ4",
            "name": "text",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "subject",
            "id": "Prompt Template-65R9W",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "xy-edge__TextInput-G1fZ4{œdataTypeœ:œTextInputœ,œidœ:œTextInput-G1fZ4œ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-Prompt Template-65R9W{œfieldNameœ:œsubjectœ,œidœ:œPrompt Template-65R9Wœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "TextInput-G1fZ4",
        "sourceHandle": "{œdataTypeœ:œTextInputœ,œidœ:œTextInput-G1fZ4œ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}",
        "target": "Prompt Template-65R9W",
        "targetHandle": "{œfieldNameœ:œsubjectœ,œidœ:œPrompt Template-65R9Wœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "TextInput",
            "id": "TextInput-1yeOx",
            "name": "text",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "num_questions",
            "id": "Prompt Template-65R9W",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "xy-edge__TextInput-1yeOx{œdataTypeœ:œTextInputœ,œidœ:œTextInput-1yeOxœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-Prompt Template-65R9W{œfieldNameœ:œnum_questionsœ,œidœ:œPrompt Template-65R9Wœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "TextInput-1yeOx",
        "sourceHandle": "{œdataTypeœ:œTextInputœ,œidœ:œTextInput-1yeOxœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}",
        "target": "Prompt Template-65R9W",
        "targetHandle": "{œfieldNameœ:œnum_questionsœ,œidœ:œPrompt Template-65R9Wœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "TextInput",
            "id": "TextInput-bfqxJ",
            "name": "text",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "difficulty_label",
            "id": "Prompt Template-65R9W",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "xy-edge__TextInput-bfqxJ{œdataTypeœ:œTextInputœ,œidœ:œTextInput-bfqxJœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-Prompt Template-65R9W{œfieldNameœ:œdifficulty_labelœ,œidœ:œPrompt Template-65R9Wœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "TextInput-bfqxJ",
        "sourceHandle": "{œdataTypeœ:œTextInputœ,œidœ:œTextInput-bfqxJœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}",
        "target": "Prompt Template-65R9W",
        "targetHandle": "{œfieldNameœ:œdifficulty_labelœ,œidœ:œPrompt Template-65R9Wœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "LanguageModelComponent",
            "id": "LanguageModelComponent-9qPkX",
            "name": "text_output",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "input_value",
            "id": "TextOutput-XVyO2",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "xy-edge__LanguageModelComponent-9qPkX{œdataTypeœ:œLanguageModelComponentœ,œidœ:œLanguageModelComponent-9qPkXœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}-TextOutput-XVyO2{œfieldNameœ:œinput_valueœ,œidœ:œTextOutput-XVyO2œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "LanguageModelComponent-9qPkX",
        "sourceHandle": "{œdataTypeœ:œLanguageModelComponentœ,œidœ:œLanguageModelComponent-9qPkXœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}",
        "target": "TextOutput-XVyO2",
        "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œTextOutput-XVyO2œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "Prompt Template",
            "id": "Prompt Template-65R9W",
            "name": "prompt",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "input_value",
            "id": "LanguageModelComponent-jQOdc",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "xy-edge__Prompt Template-65R9W{œdataTypeœ:œPrompt Templateœ,œidœ:œPrompt Template-65R9Wœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}-LanguageModelComponent-jQOdc{œfieldNameœ:œinput_valueœ,œidœ:œLanguageModelComponent-jQOdcœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "Prompt Template-65R9W",
        "sourceHandle": "{œdataTypeœ:œPrompt Templateœ,œidœ:œPrompt Template-65R9Wœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}",
        "target": "LanguageModelComponent-jQOdc",
        "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œLanguageModelComponent-jQOdcœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "LanguageModelComponent",
            "id": "LanguageModelComponent-jQOdc",
            "name": "text_output",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "input_value",
            "id": "TextOutput-fsKDZ",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "xy-edge__LanguageModelComponent-jQOdc{œdataTypeœ:œLanguageModelComponentœ,œidœ:œLanguageModelComponent-jQOdcœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}-TextOutput-fsKDZ{œfieldNameœ:œinput_valueœ,œidœ:œTextOutput-fsKDZœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "LanguageModelComponent-jQOdc",
        "sourceHandle": "{œdataTypeœ:œLanguageModelComponentœ,œidœ:œLanguageModelComponent-jQOdcœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}",
        "target": "TextOutput-fsKDZ",
        "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œTextOutput-fsKDZœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "TextInput",
            "id": "TextInput-ZFx6E",
            "name": "text",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "topic",
            "id": "Prompt Template-65R9W",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "xy-edge__TextInput-ZFx6E{œdataTypeœ:œTextInputœ,œidœ:œTextInput-ZFx6Eœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-Prompt Template-65R9W{œfieldNameœ:œtopicœ,œidœ:œPrompt Template-65R9Wœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "TextInput-ZFx6E",
        "sourceHandle": "{œdataTypeœ:œTextInputœ,œidœ:œTextInput-ZFx6Eœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}",
        "target": "Prompt Template-65R9W",
        "targetHandle": "{œfieldNameœ:œtopicœ,œidœ:œPrompt Template-65R9Wœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "TextOutput",
            "id": "TextOutput-XVyO2",
            "name": "text",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "input_value",
            "id": "CustomComponent-L21Uh",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "xy-edge__TextOutput-XVyO2{œdataTypeœ:œTextOutputœ,œidœ:œTextOutput-XVyO2œ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-CustomComponent-L21Uh{œfieldNameœ:œinput_valueœ,œidœ:œCustomComponent-L21Uhœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "TextOutput-XVyO2",
        "sourceHandle": "{œdataTypeœ:œTextOutputœ,œidœ:œTextOutput-XVyO2œ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}",
        "target": "CustomComponent-L21Uh",
        "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œCustomComponent-L21Uhœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "CustomComponent",
            "id": "CustomComponent-L21Uh",
            "name": "output",
            "output_types": [
              "Data"
            ]
          },
          "targetHandle": {
            "fieldName": "body",
            "id": "APIRequest-OMq9W",
            "inputTypes": [
              "Data"
            ],
            "type": "table"
          }
        },
        "id": "xy-edge__CustomComponent-L21Uh{œdataTypeœ:œCustomComponentœ,œidœ:œCustomComponent-L21Uhœ,œnameœ:œoutputœ,œoutput_typesœ:[œDataœ]}-APIRequest-OMq9W{œfieldNameœ:œbodyœ,œidœ:œAPIRequest-OMq9Wœ,œinputTypesœ:[œDataœ],œtypeœ:œtableœ}",
        "selected": false,
        "source": "CustomComponent-L21Uh",
        "sourceHandle": "{œdataTypeœ:œCustomComponentœ,œidœ:œCustomComponent-L21Uhœ,œnameœ:œoutputœ,œoutput_typesœ:[œDataœ]}",
        "target": "APIRequest-OMq9W",
        "targetHandle": "{œfieldNameœ:œbodyœ,œidœ:œAPIRequest-OMq9Wœ,œinputTypesœ:[œDataœ],œtypeœ:œtableœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "TextInput",
            "id": "TextInput-bfqxJ",
            "name": "text",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "difficulty",
            "id": "Prompt Template-fmpvn",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "xy-edge__TextInput-bfqxJ{œdataTypeœ:œTextInputœ,œidœ:œTextInput-bfqxJœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-Prompt Template-fmpvn{œfieldNameœ:œdifficultyœ,œidœ:œPrompt Template-fmpvnœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "TextInput-bfqxJ",
        "sourceHandle": "{œdataTypeœ:œTextInputœ,œidœ:œTextInput-bfqxJœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}",
        "target": "Prompt Template-fmpvn",
        "targetHandle": "{œfieldNameœ:œdifficultyœ,œidœ:œPrompt Template-fmpvnœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "TextInput",
            "id": "TextInput-1yeOx",
            "name": "text",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "num_questions",
            "id": "Prompt Template-fmpvn",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "xy-edge__TextInput-1yeOx{œdataTypeœ:œTextInputœ,œidœ:œTextInput-1yeOxœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-Prompt Template-fmpvn{œfieldNameœ:œnum_questionsœ,œidœ:œPrompt Template-fmpvnœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "TextInput-1yeOx",
        "sourceHandle": "{œdataTypeœ:œTextInputœ,œidœ:œTextInput-1yeOxœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}",
        "target": "Prompt Template-fmpvn",
        "targetHandle": "{œfieldNameœ:œnum_questionsœ,œidœ:œPrompt Template-fmpvnœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "TextInput",
            "id": "TextInput-G1fZ4",
            "name": "text",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "subject",
            "id": "Prompt Template-fmpvn",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "xy-edge__TextInput-G1fZ4{œdataTypeœ:œTextInputœ,œidœ:œTextInput-G1fZ4œ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-Prompt Template-fmpvn{œfieldNameœ:œsubjectœ,œidœ:œPrompt Template-fmpvnœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "TextInput-G1fZ4",
        "sourceHandle": "{œdataTypeœ:œTextInputœ,œidœ:œTextInput-G1fZ4œ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}",
        "target": "Prompt Template-fmpvn",
        "targetHandle": "{œfieldNameœ:œsubjectœ,œidœ:œPrompt Template-fmpvnœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "TextInput",
            "id": "TextInput-ZFx6E",
            "name": "text",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "topic",
            "id": "Prompt Template-fmpvn",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "xy-edge__TextInput-ZFx6E{œdataTypeœ:œTextInputœ,œidœ:œTextInput-ZFx6Eœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-Prompt Template-fmpvn{œfieldNameœ:œtopicœ,œidœ:œPrompt Template-fmpvnœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "TextInput-ZFx6E",
        "sourceHandle": "{œdataTypeœ:œTextInputœ,œidœ:œTextInput-ZFx6Eœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}",
        "target": "Prompt Template-fmpvn",
        "targetHandle": "{œfieldNameœ:œtopicœ,œidœ:œPrompt Template-fmpvnœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ConditionalRouter",
            "id": "ConditionalRouter-eF8eZ",
            "name": "false_result",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "question_output",
            "id": "Prompt Template-fmpvn",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "xy-edge__ConditionalRouter-eF8eZ{œdataTypeœ:œConditionalRouterœ,œidœ:œConditionalRouter-eF8eZœ,œnameœ:œfalse_resultœ,œoutput_typesœ:[œMessageœ]}-Prompt Template-fmpvn{œfieldNameœ:œquestion_outputœ,œidœ:œPrompt Template-fmpvnœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "ConditionalRouter-eF8eZ",
        "sourceHandle": "{œdataTypeœ:œConditionalRouterœ,œidœ:œConditionalRouter-eF8eZœ,œnameœ:œfalse_resultœ,œoutput_typesœ:[œMessageœ]}",
        "target": "Prompt Template-fmpvn",
        "targetHandle": "{œfieldNameœ:œquestion_outputœ,œidœ:œPrompt Template-fmpvnœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "PythonREPLComponent",
            "id": "PythonREPLComponent-2yl0o",
            "name": "results",
            "output_types": [
              "Data"
            ]
          },
          "targetHandle": {
            "fieldName": "data",
            "id": "CustomComponent-7CHYp",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          }
        },
        "id": "xy-edge__PythonREPLComponent-2yl0o{œdataTypeœ:œPythonREPLComponentœ,œidœ:œPythonREPLComponent-2yl0oœ,œnameœ:œresultsœ,œoutput_typesœ:[œDataœ]}-CustomComponent-7CHYp{œfieldNameœ:œdataœ,œidœ:œCustomComponent-7CHYpœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "PythonREPLComponent-2yl0o",
        "sourceHandle": "{œdataTypeœ:œPythonREPLComponentœ,œidœ:œPythonREPLComponent-2yl0oœ,œnameœ:œresultsœ,œoutput_typesœ:[œDataœ]}",
        "target": "CustomComponent-7CHYp",
        "targetHandle": "{œfieldNameœ:œdataœ,œidœ:œCustomComponent-7CHYpœ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "DataToMessageComponent",
            "id": "CustomComponent-7CHYp",
            "name": "message",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "python_code",
            "id": "PythonREPLComponent-oGIp4",
            "inputTypes": [
              "Message"
            ],
            "type": "code"
          }
        },
        "id": "xy-edge__CustomComponent-7CHYp{œdataTypeœ:œDataToMessageComponentœ,œidœ:œCustomComponent-7CHYpœ,œnameœ:œmessageœ,œoutput_typesœ:[œMessageœ]}-PythonREPLComponent-oGIp4{œfieldNameœ:œpython_codeœ,œidœ:œPythonREPLComponent-oGIp4œ,œinputTypesœ:[œMessageœ],œtypeœ:œcodeœ}",
        "selected": false,
        "source": "CustomComponent-7CHYp",
        "sourceHandle": "{œdataTypeœ:œDataToMessageComponentœ,œidœ:œCustomComponent-7CHYpœ,œnameœ:œmessageœ,œoutput_typesœ:[œMessageœ]}",
        "target": "PythonREPLComponent-oGIp4",
        "targetHandle": "{œfieldNameœ:œpython_codeœ,œidœ:œPythonREPLComponent-oGIp4œ,œinputTypesœ:[œMessageœ],œtypeœ:œcodeœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "LanguageModelComponent",
            "id": "LanguageModelComponent-k4nuc",
            "name": "text_output",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "python_code",
            "id": "PythonREPLComponent-2yl0o",
            "inputTypes": [
              "Message"
            ],
            "type": "code"
          }
        },
        "id": "xy-edge__LanguageModelComponent-k4nuc{œdataTypeœ:œLanguageModelComponentœ,œidœ:œLanguageModelComponent-k4nucœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}-PythonREPLComponent-2yl0o{œfieldNameœ:œpython_codeœ,œidœ:œPythonREPLComponent-2yl0oœ,œinputTypesœ:[œMessageœ],œtypeœ:œcodeœ}",
        "selected": false,
        "source": "LanguageModelComponent-k4nuc",
        "sourceHandle": "{œdataTypeœ:œLanguageModelComponentœ,œidœ:œLanguageModelComponent-k4nucœ,œnameœ:œtext_outputœ,œoutput_typesœ:[œMessageœ]}",
        "target": "PythonREPLComponent-2yl0o",
        "targetHandle": "{œfieldNameœ:œpython_codeœ,œidœ:œPythonREPLComponent-2yl0oœ,œinputTypesœ:[œMessageœ],œtypeœ:œcodeœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "Prompt Template",
            "id": "Prompt Template-fmpvn",
            "name": "prompt",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "input_value",
            "id": "LanguageModelComponent-k4nuc",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "xy-edge__Prompt Template-fmpvn{œdataTypeœ:œPrompt Templateœ,œidœ:œPrompt Template-fmpvnœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}-LanguageModelComponent-k4nuc{œfieldNameœ:œinput_valueœ,œidœ:œLanguageModelComponent-k4nucœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "Prompt Template-fmpvn",
        "sourceHandle": "{œdataTypeœ:œPrompt Templateœ,œidœ:œPrompt Template-fmpvnœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}",
        "target": "LanguageModelComponent-k4nuc",
        "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œLanguageModelComponent-k4nucœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "PythonREPLComponent",
            "id": "PythonREPLComponent-oGIp4",
            "name": "results",
            "output_types": [
              "Data"
            ]
          },
          "targetHandle": {
            "fieldName": "data",
            "id": "CustomComponent-jNho1",
            "inputTypes": [
              "Data"
            ],
            "type": "other"
          }
        },
        "id": "xy-edge__PythonREPLComponent-oGIp4{œdataTypeœ:œPythonREPLComponentœ,œidœ:œPythonREPLComponent-oGIp4œ,œnameœ:œresultsœ,œoutput_typesœ:[œDataœ]}-CustomComponent-jNho1{œfieldNameœ:œdataœ,œidœ:œCustomComponent-jNho1œ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}",
        "selected": false,
        "source": "PythonREPLComponent-oGIp4",
        "sourceHandle": "{œdataTypeœ:œPythonREPLComponentœ,œidœ:œPythonREPLComponent-oGIp4œ,œnameœ:œresultsœ,œoutput_typesœ:[œDataœ]}",
        "target": "CustomComponent-jNho1",
        "targetHandle": "{œfieldNameœ:œdataœ,œidœ:œCustomComponent-jNho1œ,œinputTypesœ:[œDataœ],œtypeœ:œotherœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "ConditionalRouter",
            "id": "ConditionalRouter-eF8eZ",
            "name": "true_result",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "input_value",
            "id": "TextOutput-ujpFk",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "xy-edge__ConditionalRouter-eF8eZ{œdataTypeœ:œConditionalRouterœ,œidœ:œConditionalRouter-eF8eZœ,œnameœ:œtrue_resultœ,œoutput_typesœ:[œMessageœ]}-TextOutput-ujpFk{œfieldNameœ:œinput_valueœ,œidœ:œTextOutput-ujpFkœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "ConditionalRouter-eF8eZ",
        "sourceHandle": "{œdataTypeœ:œConditionalRouterœ,œidœ:œConditionalRouter-eF8eZœ,œnameœ:œtrue_resultœ,œoutput_typesœ:[œMessageœ]}",
        "target": "TextOutput-ujpFk",
        "targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œTextOutput-ujpFkœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      },
      {
        "animated": false,
        "className": "",
        "data": {
          "sourceHandle": {
            "dataType": "TextOutput",
            "id": "TextOutput-Q2X4H",
            "name": "text",
            "output_types": [
              "Message"
            ]
          },
          "targetHandle": {
            "fieldName": "feedback",
            "id": "Prompt Template-fmpvn",
            "inputTypes": [
              "Message"
            ],
            "type": "str"
          }
        },
        "id": "xy-edge__TextOutput-Q2X4H{œdataTypeœ:œTextOutputœ,œidœ:œTextOutput-Q2X4Hœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}-Prompt Template-fmpvn{œfieldNameœ:œfeedbackœ,œidœ:œPrompt Template-fmpvnœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
        "selected": false,
        "source": "TextOutput-Q2X4H",
        "sourceHandle": "{œdataTypeœ:œTextOutputœ,œidœ:œTextOutput-Q2X4Hœ,œnameœ:œtextœ,œoutput_typesœ:[œMessageœ]}",
        "target": "Prompt Template-fmpvn",
        "targetHandle": "{œfieldNameœ:œfeedbackœ,œidœ:œPrompt Template-fmpvnœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}"
      }
    ],
    "nodes": [
      {
        "data": {
          "id": "TextInput-ZM95Q",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Get user text inputs.",
            "display_name": "age",
            "documentation": "https://docs.langflow.org/components-io#text-input",
            "edited": false,
            "field_order": [
              "input_value"
            ],
            "frozen": false,
            "icon": "type",
            "legacy": false,
            "lf_version": "1.5.0",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Output Text",
                "group_outputs": false,
                "method": "text_response",
                "name": "text",
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.base.io.text import TextComponent\nfrom langflow.io import MultilineInput, Output\nfrom langflow.schema.message import Message\n\n\nclass TextInputComponent(TextComponent):\n    display_name = \"Text Input\"\n    description = \"Get user text inputs.\"\n    documentation: str = \"https://docs.langflow.org/components-io#text-input\"\n    icon = \"type\"\n    name = \"TextInput\"\n\n    inputs = [\n        MultilineInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            info=\"Text to be passed as input.\",\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Output Text\", name=\"text\", method=\"text_response\"),\n    ]\n\n    def text_response(self) -> Message:\n        return Message(\n            text=self.input_value,\n        )\n"
              },
              "input_value": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "copy_field": false,
                "display_name": "Text",
                "dynamic": false,
                "info": "Text to be passed as input.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "input_value",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "22"
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "TextInput"
        },
        "dragging": false,
        "id": "TextInput-ZM95Q",
        "measured": {
          "height": 201,
          "width": 320
        },
        "position": {
          "x": -1511.903396835282,
          "y": 36.4798659057695
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "TextInput-zHjdu",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Get user text inputs.",
            "display_name": "knowledge level",
            "documentation": "https://docs.langflow.org/components-io#text-input",
            "edited": false,
            "field_order": [
              "input_value"
            ],
            "frozen": false,
            "icon": "type",
            "legacy": false,
            "lf_version": "1.5.0",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Output Text",
                "group_outputs": false,
                "method": "text_response",
                "name": "text",
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.base.io.text import TextComponent\nfrom langflow.io import MultilineInput, Output\nfrom langflow.schema.message import Message\n\n\nclass TextInputComponent(TextComponent):\n    display_name = \"Text Input\"\n    description = \"Get user text inputs.\"\n    documentation: str = \"https://docs.langflow.org/components-io#text-input\"\n    icon = \"type\"\n    name = \"TextInput\"\n\n    inputs = [\n        MultilineInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            info=\"Text to be passed as input.\",\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Output Text\", name=\"text\", method=\"text_response\"),\n    ]\n\n    def text_response(self) -> Message:\n        return Message(\n            text=self.input_value,\n        )\n"
              },
              "input_value": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "copy_field": false,
                "display_name": "Text",
                "dynamic": false,
                "info": "Text to be passed as input.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "input_value",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "4"
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "TextInput"
        },
        "dragging": false,
        "id": "TextInput-zHjdu",
        "measured": {
          "height": 201,
          "width": 320
        },
        "position": {
          "x": -2147.5692605538984,
          "y": 762.4908350924102
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "Prompt Template-iiNjI",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {
              "template": [
                "age",
                "experience",
                "level",
                "question"
              ]
            },
            "description": "Create a prompt template with dynamic variables.",
            "display_name": "Prompt Template",
            "documentation": "https://docs.langflow.org/components-prompts",
            "edited": true,
            "error": null,
            "field_order": [
              "template",
              "tool_placeholder"
            ],
            "frozen": false,
            "full_path": null,
            "icon": "braces",
            "is_composition": null,
            "is_input": null,
            "is_output": null,
            "legacy": false,
            "lf_version": "1.5.0",
            "metadata": {},
            "minimized": false,
            "name": "",
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Prompt",
                "group_outputs": false,
                "hidden": null,
                "method": "build_prompt",
                "name": "prompt",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "priority": 0,
            "template": {
              "_type": "Component",
              "age": {
                "advanced": false,
                "display_name": "age",
                "dynamic": false,
                "field_type": "str",
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "age",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": ""
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.base.prompts.api_utils import process_prompt_template\r\nfrom langflow.custom.custom_component.component import Component\r\nfrom langflow.inputs.inputs import DefaultPromptField\r\nfrom langflow.io import MessageTextInput, Output, PromptInput\r\nfrom langflow.schema.message import Message\r\nfrom langflow.template.utils import update_template_values\r\n\r\n\r\nclass PromptComponent(Component):\r\n    display_name: str = \"Prompt Template\"\r\n    description: str = \"Create a prompt template with dynamic variables.\"\r\n    documentation: str = \"https://docs.langflow.org/components-prompts\"\r\n    icon = \"braces\"\r\n    trace_type = \"prompt\"\r\n    name = \"Prompt Template\"\r\n    priority = 0  # Set priority to 0 to make it appear first\r\n\r\n    inputs = [\r\n        PromptInput(name=\"template\", display_name=\"Template\"),\r\n        MessageTextInput(\r\n            name=\"tool_placeholder\",\r\n            display_name=\"Tool Placeholder\",\r\n            tool_mode=True,\r\n            advanced=True,\r\n            info=\"A placeholder input for tool mode.\",\r\n        ),\r\n    ]\r\n\r\n    outputs = [\r\n        Output(display_name=\"Prompt\", name=\"prompt\", method=\"build_prompt\"),\r\n    ]\r\n\r\n    async def build_prompt(self) -> Message:\r\n        prompt = Message.from_template(**self._attributes)\r\n        self.status = prompt.text\r\n        return prompt\r\n\r\n    def _update_template(self, frontend_node: dict):\r\n        prompt_template = frontend_node[\"template\"][\"template\"][\"value\"]\r\n        custom_fields = frontend_node[\"custom_fields\"]\r\n        frontend_node_template = frontend_node[\"template\"]\r\n        _ = process_prompt_template(\r\n            template=prompt_template,\r\n            name=\"template\",\r\n            custom_fields=custom_fields,\r\n            frontend_node_template=frontend_node_template,\r\n        )\r\n        return frontend_node\r\n\r\n    async def update_frontend_node(self, new_frontend_node: dict, current_frontend_node: dict):\r\n        \"\"\"This function is called after the code validation is done.\"\"\"\r\n        frontend_node = await super().update_frontend_node(new_frontend_node, current_frontend_node)\r\n        template = frontend_node[\"template\"][\"template\"][\"value\"]\r\n        # Kept it duplicated for backwards compatibility\r\n        _ = process_prompt_template(\r\n            template=template,\r\n            name=\"template\",\r\n            custom_fields=frontend_node[\"custom_fields\"],\r\n            frontend_node_template=frontend_node[\"template\"],\r\n        )\r\n        # Now that template is updated, we need to grab any values that were set in the current_frontend_node\r\n        # and update the frontend_node with those values\r\n        update_template_values(new_template=frontend_node, previous_template=current_frontend_node[\"template\"])\r\n        return frontend_node\r\n\r\n    def _get_fallback_input(self, **kwargs):\r\n        return DefaultPromptField(**kwargs)"
              },
              "experience": {
                "advanced": false,
                "display_name": "experience",
                "dynamic": false,
                "field_type": "str",
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "experience",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": ""
              },
              "level": {
                "advanced": false,
                "display_name": "level",
                "dynamic": false,
                "field_type": "str",
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "level",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": ""
              },
              "question": {
                "advanced": false,
                "display_name": "question",
                "dynamic": false,
                "field_type": "str",
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "question",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": ""
              },
              "template": {
                "_input_type": "PromptInput",
                "advanced": false,
                "display_name": "Template",
                "dynamic": false,
                "info": "",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "template",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "type": "prompt",
                "value": "User Information:\n- Age: {age}\n- Years of Experience: {experience}\n- Knowledge Level (1=Beginner to 5=Expert): {level}\n\nQuestion: {question}\n\nPlease respond in a professional and informative tone.\n"
              },
              "tool_placeholder": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Tool Placeholder",
                "dynamic": false,
                "info": "A placeholder input for tool mode.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "tool_placeholder",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "Prompt Template"
        },
        "dragging": false,
        "id": "Prompt Template-iiNjI",
        "measured": {
          "height": 609,
          "width": 320
        },
        "position": {
          "x": -904.3808645190587,
          "y": 424.71936261256485
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "TextInput-YAms8",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "category": "input_output",
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Get user text inputs.",
            "display_name": "experience",
            "documentation": "https://docs.langflow.org/components-io#text-input",
            "edited": false,
            "field_order": [
              "input_value"
            ],
            "frozen": false,
            "icon": "type",
            "key": "TextInput",
            "legacy": false,
            "lf_version": "1.5.0",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Output Text",
                "group_outputs": false,
                "method": "text_response",
                "name": "text",
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "score": 0.0022704986850629236,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.base.io.text import TextComponent\nfrom langflow.io import MultilineInput, Output\nfrom langflow.schema.message import Message\n\n\nclass TextInputComponent(TextComponent):\n    display_name = \"Text Input\"\n    description = \"Get user text inputs.\"\n    documentation: str = \"https://docs.langflow.org/components-io#text-input\"\n    icon = \"type\"\n    name = \"TextInput\"\n\n    inputs = [\n        MultilineInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            info=\"Text to be passed as input.\",\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Output Text\", name=\"text\", method=\"text_response\"),\n    ]\n\n    def text_response(self) -> Message:\n        return Message(\n            text=self.input_value,\n        )\n"
              },
              "input_value": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "copy_field": false,
                "display_name": "Text",
                "dynamic": false,
                "info": "Text to be passed as input.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "input_value",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "5"
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "TextInput"
        },
        "dragging": false,
        "id": "TextInput-YAms8",
        "measured": {
          "height": 201,
          "width": 320
        },
        "position": {
          "x": -1913.283918278696,
          "y": 391.6165614906575
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "TextInput-p6OwG",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "category": "input_output",
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Get user text inputs.",
            "display_name": "question",
            "documentation": "https://docs.langflow.org/components-io#text-input",
            "edited": false,
            "field_order": [
              "input_value"
            ],
            "frozen": false,
            "icon": "type",
            "key": "TextInput",
            "legacy": false,
            "lf_version": "1.5.0",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Output Text",
                "group_outputs": false,
                "method": "text_response",
                "name": "text",
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "score": 0.0022704986850629236,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.base.io.text import TextComponent\nfrom langflow.io import MultilineInput, Output\nfrom langflow.schema.message import Message\n\n\nclass TextInputComponent(TextComponent):\n    display_name = \"Text Input\"\n    description = \"Get user text inputs.\"\n    documentation: str = \"https://docs.langflow.org/components-io#text-input\"\n    icon = \"type\"\n    name = \"TextInput\"\n\n    inputs = [\n        MultilineInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            info=\"Text to be passed as input.\",\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Output Text\", name=\"text\", method=\"text_response\"),\n    ]\n\n    def text_response(self) -> Message:\n        return Message(\n            text=self.input_value,\n        )\n"
              },
              "input_value": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "copy_field": false,
                "display_name": "Text",
                "dynamic": false,
                "info": "Text to be passed as input.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "input_value",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "what is langflow ?"
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "TextInput"
        },
        "dragging": false,
        "id": "TextInput-p6OwG",
        "measured": {
          "height": 201,
          "width": 320
        },
        "position": {
          "x": -2143.80170984395,
          "y": 1078.7708049741389
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "CustomComponent-7CHYp",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Extracts a message string from API response data and outputs as a Message object.",
            "display_name": "Data to Message",
            "documentation": "https://docs.langflow.org/components-custom-components",
            "edited": true,
            "field_order": [
              "data"
            ],
            "frozen": false,
            "icon": "message",
            "legacy": false,
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Message",
                "group_outputs": false,
                "hidden": null,
                "method": "build_message",
                "name": "message",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.custom.custom_component.component import Component\r\nfrom langflow.io import DataInput, Output\r\nfrom langflow.schema.message import Message  # Import the Message class\r\n\r\nclass DataToMessageComponent(Component):\r\n    display_name = \"Data to Message\"\r\n    description = \"Extracts a message string from API response data and outputs as a Message object.\"\r\n    documentation: str = \"https://docs.langflow.org/components-custom-components\"\r\n    icon = \"message\"\r\n    name = \"DataToMessageComponent\"\r\n\r\n    inputs = [\r\n        DataInput(\r\n            name=\"data\",\r\n            display_name=\"Data\",\r\n            info=\"API response data (dict, JSON, or text).\",\r\n            value={},\r\n            tool_mode=True,\r\n        ),\r\n    ]\r\n\r\n    outputs = [\r\n        Output(display_name=\"Message\", name=\"message\", method=\"build_message\"),\r\n    ]\r\n\r\n    def build_message(self) -> Message:\r\n        data = self.data\r\n        # Try to extract the message from common API response structures\r\n        if isinstance(data, dict):\r\n            if \"data\" in data and \"message\" in data[\"data\"]:\r\n                msg = data[\"data\"][\"message\"]\r\n            elif \"message\" in data:\r\n                msg = data[\"message\"]\r\n            else:\r\n                msg = str(data)\r\n        else:\r\n            msg = str(data)\r\n        return Message(content=msg)  # Output as a Message object\r\n"
              },
              "data": {
                "_input_type": "DataInput",
                "advanced": false,
                "display_name": "Data",
                "dynamic": false,
                "info": "API response data (dict, JSON, or text).",
                "input_types": [
                  "Data"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "data",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "other",
                "value": {}
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "DataToMessageComponent"
        },
        "dragging": false,
        "id": "CustomComponent-7CHYp",
        "measured": {
          "height": 180,
          "width": 320
        },
        "position": {
          "x": 5249.328318365066,
          "y": -788.401695259136
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "APIRequest-OMq9W",
          "node": {
            "base_classes": [
              "Data"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Make HTTP requests using URL or cURL commands.",
            "display_name": "API Request",
            "documentation": "https://docs.langflow.org/components-data#api-request",
            "edited": true,
            "field_order": [
              "url_input",
              "curl_input",
              "method",
              "mode",
              "query_params",
              "body",
              "headers",
              "timeout",
              "follow_redirects",
              "save_to_file",
              "include_httpx_metadata"
            ],
            "frozen": false,
            "icon": "Globe",
            "last_updated": "2025-07-24T10:06:39.469Z",
            "legacy": false,
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "API Response",
                "group_outputs": false,
                "hidden": null,
                "method": "make_api_request",
                "name": "data",
                "options": null,
                "required_inputs": null,
                "selected": "Data",
                "tool_mode": true,
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "body": {
                "_input_type": "TableInput",
                "advanced": false,
                "display_name": "Body",
                "dynamic": false,
                "info": "The body to send with the request as a dictionary (for POST, PATCH, PUT).",
                "input_types": [
                  "Data"
                ],
                "is_list": true,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "body",
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "table_icon": "Table",
                "table_schema": {
                  "columns": [
                    {
                      "default": "None",
                      "description": "Parameter name",
                      "disable_edit": false,
                      "display_name": "Key",
                      "edit_mode": "popover",
                      "filterable": true,
                      "formatter": "text",
                      "hidden": false,
                      "name": "key",
                      "sortable": true,
                      "type": "str"
                    },
                    {
                      "default": "None",
                      "description": "Parameter value",
                      "disable_edit": false,
                      "display_name": "Value",
                      "edit_mode": "popover",
                      "filterable": true,
                      "formatter": "text",
                      "hidden": false,
                      "name": "value",
                      "sortable": true
                    }
                  ]
                },
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "trigger_icon": "Table",
                "trigger_text": "Open table",
                "type": "table",
                "value": [
                  {
                    "key": "model",
                    "value": "llama2"
                  },
                  {
                    "key": "prompt",
                    "value": "\"Age: {age}, Level: {level}, Experience: {experience}, Question: {question}\""
                  },
                  {
                    "key": "stream",
                    "value": "False"
                  }
                ]
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "import json\r\nimport re\r\nimport tempfile\r\nfrom datetime import datetime, timezone\r\nfrom pathlib import Path\r\nfrom typing import Any\r\nfrom urllib.parse import parse_qsl, urlencode, urlparse, urlunparse\r\n\r\nimport aiofiles\r\nimport aiofiles.os as aiofiles_os\r\nimport httpx\r\nimport validators\r\n\r\nfrom langflow.base.curl.parse import parse_context\r\nfrom langflow.custom.custom_component.component import Component\r\nfrom langflow.inputs.inputs import TabInput\r\nfrom langflow.io import (\r\n    BoolInput,\r\n    DataInput,\r\n    DropdownInput,\r\n    IntInput,\r\n    MessageTextInput,\r\n    MultilineInput,\r\n    Output,\r\n    TableInput,\r\n)\r\nfrom langflow.schema.data import Data\r\nfrom langflow.schema.dotdict import dotdict\r\nfrom langflow.services.deps import get_settings_service\r\nfrom langflow.utils.component_utils import set_current_fields, set_field_advanced, set_field_display\r\n\r\n# Define fields for each mode\r\nMODE_FIELDS = {\r\n    \"URL\": [\r\n        \"url_input\",\r\n        \"method\",\r\n    ],\r\n    \"cURL\": [\"curl_input\"],\r\n}\r\n\r\n# Fields that should always be visible\r\nDEFAULT_FIELDS = [\"mode\"]\r\n\r\n\r\nclass APIRequestComponent(Component):\r\n    display_name = \"API Request\"\r\n    description = \"Make HTTP requests using URL or cURL commands.\"\r\n    documentation: str = \"https://docs.langflow.org/components-data#api-request\"\r\n    icon = \"Globe\"\r\n    name = \"APIRequest\"\r\n\r\n    inputs = [\r\n        MessageTextInput(\r\n            name=\"url_input\",\r\n            display_name=\"URL\",\r\n            info=\"Enter the URL for the request.\",\r\n            advanced=False,\r\n            tool_mode=True,\r\n        ),\r\n        MultilineInput(\r\n            name=\"curl_input\",\r\n            display_name=\"cURL\",\r\n            info=(\r\n                \"Paste a curl command to populate the fields. \"\r\n                \"This will fill in the dictionary fields for headers and body.\"\r\n            ),\r\n            real_time_refresh=True,\r\n            tool_mode=True,\r\n            advanced=True,\r\n            show=False,\r\n        ),\r\n        DropdownInput(\r\n            name=\"method\",\r\n            display_name=\"Method\",\r\n            options=[\"GET\", \"POST\", \"PATCH\", \"PUT\", \"DELETE\"],\r\n            value=\"GET\",\r\n            info=\"The HTTP method to use.\",\r\n            real_time_refresh=True,\r\n        ),\r\n        TabInput(\r\n            name=\"mode\",\r\n            display_name=\"Mode\",\r\n            options=[\"URL\", \"cURL\"],\r\n            value=\"URL\",\r\n            info=\"Enable cURL mode to populate fields from a cURL command.\",\r\n            real_time_refresh=True,\r\n        ),\r\n        DataInput(\r\n            name=\"query_params\",\r\n            display_name=\"Query Parameters\",\r\n            info=\"The query parameters to append to the URL.\",\r\n            advanced=True,\r\n        ),\r\n        TableInput(\r\n            name=\"body\",\r\n            display_name=\"Body\",\r\n            info=\"The body to send with the request as a dictionary (for POST, PATCH, PUT).\",\r\n            table_schema=[\r\n                {\r\n                    \"name\": \"key\",\r\n                    \"display_name\": \"Key\",\r\n                    \"type\": \"str\",\r\n                    \"description\": \"Parameter name\",\r\n                },\r\n                {\r\n                    \"name\": \"value\",\r\n                    \"display_name\": \"Value\",\r\n                    \"description\": \"Parameter value\",\r\n                },\r\n            ],\r\n            value=[],\r\n            input_types=[\"Data\"],\r\n            advanced=True,\r\n            real_time_refresh=True,\r\n        ),\r\n        TableInput(\r\n            name=\"headers\",\r\n            display_name=\"Headers\",\r\n            info=\"The headers to send with the request\",\r\n            table_schema=[\r\n                {\r\n                    \"name\": \"key\",\r\n                    \"display_name\": \"Header\",\r\n                    \"type\": \"str\",\r\n                    \"description\": \"Header name\",\r\n                },\r\n                {\r\n                    \"name\": \"value\",\r\n                    \"display_name\": \"Value\",\r\n                    \"type\": \"str\",\r\n                    \"description\": \"Header value\",\r\n                },\r\n            ],\r\n            value=[{\"key\": \"User-Agent\", \"value\": get_settings_service().settings.user_agent}],\r\n            advanced=True,\r\n            input_types=[\"Data\"],\r\n            real_time_refresh=True,\r\n        ),\r\n        IntInput(\r\n            name=\"timeout\",\r\n            display_name=\"Timeout\",\r\n            value=30,\r\n            info=\"The timeout to use for the request.\",\r\n            advanced=True,\r\n        ),\r\n        BoolInput(\r\n            name=\"follow_redirects\",\r\n            display_name=\"Follow Redirects\",\r\n            value=True,\r\n            info=\"Whether to follow http redirects.\",\r\n            advanced=True,\r\n        ),\r\n        BoolInput(\r\n            name=\"save_to_file\",\r\n            display_name=\"Save to File\",\r\n            value=False,\r\n            info=\"Save the API response to a temporary file\",\r\n            advanced=True,\r\n        ),\r\n        BoolInput(\r\n            name=\"include_httpx_metadata\",\r\n            display_name=\"Include HTTPx Metadata\",\r\n            value=False,\r\n            info=(\r\n                \"Include properties such as headers, status_code, response_headers, \"\r\n                \"and redirection_history in the output.\"\r\n            ),\r\n            advanced=True,\r\n        ),\r\n    ]\r\n\r\n    outputs = [\r\n        Output(display_name=\"API Response\", name=\"data\", method=\"make_api_request\"),\r\n    ]\r\n\r\n    def _parse_json_value(self, value: Any) -> Any:\r\n        \"\"\"Parse a value that might be a JSON string.\"\"\"\r\n        if not isinstance(value, str):\r\n            return value\r\n\r\n        try:\r\n            parsed = json.loads(value)\r\n        except json.JSONDecodeError:\r\n            return value\r\n        else:\r\n            return parsed\r\n\r\n    def _process_body(self, body: Any) -> dict:\r\n        \"\"\"Process the body input into a valid dictionary.\"\"\"\r\n        if body is None:\r\n            return {}\r\n        if isinstance(body, dict):\r\n            return self._process_dict_body(body)\r\n        if isinstance(body, str):\r\n            return self._process_string_body(body)\r\n        if isinstance(body, list):\r\n            return self._process_list_body(body)\r\n        return {}\r\n\r\n    def _process_dict_body(self, body: dict) -> dict:\r\n        \"\"\"Process dictionary body by parsing JSON values.\"\"\"\r\n        return {k: self._parse_json_value(v) for k, v in body.items()}\r\n\r\n    def _process_string_body(self, body: str) -> dict:\r\n        \"\"\"Process string body by attempting JSON parse.\"\"\"\r\n        try:\r\n            return self._process_body(json.loads(body))\r\n        except json.JSONDecodeError:\r\n            return {\"data\": body}\r\n\r\n    def _process_list_body(self, body: list) -> dict:\r\n        \"\"\"Process list body by converting to key-value dictionary.\"\"\"\r\n        processed_dict = {}\r\n        try:\r\n            for item in body:\r\n                if not self._is_valid_key_value_item(item):\r\n                    continue\r\n                key = item[\"key\"]\r\n                value = self._parse_json_value(item[\"value\"])\r\n                processed_dict[key] = value\r\n        except (KeyError, TypeError, ValueError) as e:\r\n            self.log(f\"Failed to process body list: {e}\")\r\n            return {}\r\n        return processed_dict\r\n\r\n    def _is_valid_key_value_item(self, item: Any) -> bool:\r\n        \"\"\"Check if an item is a valid key-value dictionary.\"\"\"\r\n        return isinstance(item, dict) and \"key\" in item and \"value\" in item\r\n\r\n    def parse_curl(self, curl: str, build_config: dotdict) -> dotdict:\r\n        \"\"\"Parse a cURL command and update build configuration.\"\"\"\r\n        try:\r\n            parsed = parse_context(curl)\r\n\r\n            # Update basic configuration\r\n            url = parsed.url\r\n            # Normalize URL before setting it\r\n            url = self._normalize_url(url)\r\n\r\n            build_config[\"url_input\"][\"value\"] = url\r\n            build_config[\"method\"][\"value\"] = parsed.method.upper()\r\n\r\n            # Process headers\r\n            headers_list = [{\"key\": k, \"value\": v} for k, v in parsed.headers.items()]\r\n            build_config[\"headers\"][\"value\"] = headers_list\r\n\r\n            # Process body data\r\n            if not parsed.data:\r\n                build_config[\"body\"][\"value\"] = []\r\n            elif parsed.data:\r\n                try:\r\n                    json_data = json.loads(parsed.data)\r\n                    if isinstance(json_data, dict):\r\n                        body_list = [\r\n                            {\"key\": k, \"value\": json.dumps(v) if isinstance(v, dict | list) else str(v)}\r\n                            for k, v in json_data.items()\r\n                        ]\r\n                        build_config[\"body\"][\"value\"] = body_list\r\n                    else:\r\n                        build_config[\"body\"][\"value\"] = [{\"key\": \"data\", \"value\": json.dumps(json_data)}]\r\n                except json.JSONDecodeError:\r\n                    build_config[\"body\"][\"value\"] = [{\"key\": \"data\", \"value\": parsed.data}]\r\n\r\n        except Exception as exc:\r\n            msg = f\"Error parsing curl: {exc}\"\r\n            self.log(msg)\r\n            raise ValueError(msg) from exc\r\n\r\n        return build_config\r\n\r\n    def _normalize_url(self, url: str) -> str:\r\n        \"\"\"Normalize URL by adding https:// if no protocol is specified.\"\"\"\r\n        if not url or not isinstance(url, str):\r\n            msg = \"URL cannot be empty\"\r\n            raise ValueError(msg)\r\n\r\n        url = url.strip()\r\n        \r\n        # Check if URL is already well-formed\r\n        if url.startswith((\"http://\", \"https://\")):\r\n            return url\r\n        \r\n        # Only add https:// if it looks like a domain/IP without protocol\r\n        # Don't modify if it contains unexpected characters or patterns\r\n        if \":\" in url and not url.startswith(\"localhost\"):\r\n            # Check if it's localhost with port\r\n            if url.startswith(\"localhost:\"):\r\n                return f\"http://{url}\"\r\n            # Check if it's an IP with port\r\n            elif re.match(r\"^\\d+\\.\\d+\\.\\d+\\.\\d+:\\d+\", url):\r\n                return f\"http://{url}\"\r\n        \r\n        # For regular domains without protocol, add https://\r\n        if re.match(r\"^[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}(/.*)?$\", url):\r\n            return f\"https://{url}\"\r\n        \r\n        # If it doesn't match expected patterns, return as is\r\n        # This prevents adding protocol to invalid URLs\r\n        return url\r\n\r\n    def _validate_url_format(self, url: str) -> bool:\r\n        \"\"\"Validate that the URL has a proper format.\"\"\"\r\n        if not url or not isinstance(url, str):\r\n            return False\r\n        \r\n        url = url.strip()\r\n        \r\n        # Check for basic URL patterns\r\n        url_patterns = [\r\n            r\"^https?://\",  # Starts with http:// or https://\r\n            r\"^[a-zA-Z0-9.-]+\\.[a-zA-Z]{2,}\",  # Domain pattern\r\n            r\"^localhost(:\\d+)?\",  # localhost with optional port\r\n            r\"^\\d+\\.\\d+\\.\\d+\\.\\d+(:\\d+)?\",  # IP address with optional port\r\n        ]\r\n        \r\n        return any(re.match(pattern, url) for pattern in url_patterns)\r\n\r\n    async def make_request(\r\n        self,\r\n        client: httpx.AsyncClient,\r\n        method: str,\r\n        url: str,\r\n        headers: dict | None = None,\r\n        body: Any = None,\r\n        timeout: int = 5,\r\n        *,\r\n        follow_redirects: bool = True,\r\n        save_to_file: bool = False,\r\n        include_httpx_metadata: bool = False,\r\n    ) -> Data:\r\n        method = method.upper()\r\n        if method not in {\"GET\", \"POST\", \"PATCH\", \"PUT\", \"DELETE\"}:\r\n            msg = f\"Unsupported method: {method}\"\r\n            raise ValueError(msg)\r\n\r\n        processed_body = self._process_body(body)\r\n        redirection_history = []\r\n\r\n        try:\r\n            # Prepare request parameters\r\n            request_params = {\r\n                \"method\": method,\r\n                \"url\": url,\r\n                \"headers\": headers,\r\n                \"json\": processed_body,\r\n                \"timeout\": timeout,\r\n                \"follow_redirects\": follow_redirects,\r\n            }\r\n            response = await client.request(**request_params)\r\n\r\n            redirection_history = [\r\n                {\r\n                    \"url\": redirect.headers.get(\"Location\", str(redirect.url)),\r\n                    \"status_code\": redirect.status_code,\r\n                }\r\n                for redirect in response.history\r\n            ]\r\n\r\n            is_binary, file_path = await self._response_info(response, with_file_path=save_to_file)\r\n            response_headers = self._headers_to_dict(response.headers)\r\n\r\n            # Base metadata\r\n            metadata = {\r\n                \"source\": url,\r\n                \"status_code\": response.status_code,\r\n                \"response_headers\": response_headers,\r\n            }\r\n\r\n            if redirection_history:\r\n                metadata[\"redirection_history\"] = redirection_history\r\n\r\n            if save_to_file:\r\n                mode = \"wb\" if is_binary else \"w\"\r\n                encoding = response.encoding if mode == \"w\" else None\r\n                if file_path:\r\n                    await aiofiles_os.makedirs(file_path.parent, exist_ok=True)\r\n                    if is_binary:\r\n                        async with aiofiles.open(file_path, \"wb\") as f:\r\n                            await f.write(response.content)\r\n                            await f.flush()\r\n                    else:\r\n                        async with aiofiles.open(file_path, \"w\", encoding=encoding) as f:\r\n                            await f.write(response.text)\r\n                            await f.flush()\r\n                    metadata[\"file_path\"] = str(file_path)\r\n\r\n                if include_httpx_metadata:\r\n                    metadata.update({\"headers\": headers})\r\n                return Data(data=metadata)\r\n\r\n            # Handle response content\r\n            if is_binary:\r\n                result = response.content\r\n            else:\r\n                try:\r\n                    result = response.json()\r\n                except json.JSONDecodeError:\r\n                    self.log(\"Failed to decode JSON response\")\r\n                    result = response.text.encode(\"utf-8\")\r\n\r\n            metadata[\"result\"] = result\r\n\r\n            if include_httpx_metadata:\r\n                metadata.update({\"headers\": headers})\r\n\r\n            return Data(data=metadata)\r\n        except (httpx.HTTPError, httpx.RequestError, httpx.TimeoutException) as exc:\r\n            self.log(f\"Error making request to {url}: {exc}\")\r\n            return Data(\r\n                data={\r\n                    \"source\": url,\r\n                    \"headers\": headers,\r\n                    \"status_code\": 500,\r\n                    \"error\": str(exc),\r\n                    **({\"redirection_history\": redirection_history} if redirection_history else {}),\r\n                },\r\n            )\r\n\r\n    def add_query_params(self, url: str, params: dict) -> str:\r\n        \"\"\"Add query parameters to URL efficiently.\"\"\"\r\n        if not params:\r\n            return url\r\n        url_parts = list(urlparse(url))\r\n        query = dict(parse_qsl(url_parts[4]))\r\n        query.update(params)\r\n        url_parts[4] = urlencode(query)\r\n        return urlunparse(url_parts)\r\n\r\n    def _headers_to_dict(self, headers: httpx.Headers) -> dict[str, str]:\r\n        \"\"\"Convert HTTP headers to a dictionary with lowercased keys.\"\"\"\r\n        return {k.lower(): v for k, v in headers.items()}\r\n\r\n    def _process_headers(self, headers: Any) -> dict:\r\n        \"\"\"Process the headers input into a valid dictionary.\"\"\"\r\n        if headers is None:\r\n            return {}\r\n        if isinstance(headers, dict):\r\n            return headers\r\n        if isinstance(headers, list):\r\n            return {item[\"key\"]: item[\"value\"] for item in headers if self._is_valid_key_value_item(item)}\r\n        return {}\r\n\r\n    async def make_api_request(self) -> Data:\r\n        \"\"\"Make HTTP request with optimized parameter handling.\"\"\"\r\n        method = self.method\r\n        url = self.url_input.strip() if isinstance(self.url_input, str) else \"\"\r\n        headers = self.headers or {}\r\n        body = self.body or {}\r\n        timeout = self.timeout\r\n        follow_redirects = self.follow_redirects\r\n        save_to_file = self.save_to_file\r\n        include_httpx_metadata = self.include_httpx_metadata\r\n\r\n        # Validate URL format first\r\n        if not self._validate_url_format(url):\r\n            msg = f\"Invalid URL format: {url}. Please provide a valid URL (e.g., http://localhost:11434/api/generate)\"\r\n            self.log(msg)\r\n            raise ValueError(msg)\r\n\r\n        # Normalize URL only if it passes basic validation\r\n        try:\r\n            url = self._normalize_url(url)\r\n        except ValueError as e:\r\n            self.log(f\"URL normalization failed: {e}\")\r\n            raise\r\n\r\n        # Validate URL using validators library\r\n        if not validators.url(url):\r\n            msg = f\"Invalid URL provided: {url}. Please check the URL format and try again.\"\r\n            self.log(msg)\r\n            raise ValueError(msg)\r\n\r\n        # Process query parameters\r\n        if isinstance(self.query_params, str):\r\n            query_params = dict(parse_qsl(self.query_params))\r\n        else:\r\n            query_params = self.query_params.data if self.query_params else {}\r\n\r\n        # Process headers and body\r\n        headers = self._process_headers(headers)\r\n        body = self._process_body(body)\r\n        url = self.add_query_params(url, query_params)\r\n\r\n        async with httpx.AsyncClient() as client:\r\n            result = await self.make_request(\r\n                client,\r\n                method,\r\n                url,\r\n                headers,\r\n                body,\r\n                timeout,\r\n                follow_redirects=follow_redirects,\r\n                save_to_file=save_to_file,\r\n                include_httpx_metadata=include_httpx_metadata,\r\n            )\r\n        self.status = result\r\n        return result\r\n\r\n    def update_build_config(self, build_config: dotdict, field_value: Any, field_name: str | None = None) -> dotdict:\r\n        \"\"\"Update the build config based on the selected mode.\"\"\"\r\n        if field_name != \"mode\":\r\n            if field_name == \"curl_input\" and self.mode == \"cURL\" and self.curl_input:\r\n                return self.parse_curl(self.curl_input, build_config)\r\n            return build_config\r\n\r\n        # print(f\"Current mode: {field_value}\")\r\n        if field_value == \"cURL\":\r\n            set_field_display(build_config, \"curl_input\", value=True)\r\n            if build_config[\"curl_input\"][\"value\"]:\r\n                build_config = self.parse_curl(build_config[\"curl_input\"][\"value\"], build_config)\r\n        else:\r\n            set_field_display(build_config, \"curl_input\", value=False)\r\n\r\n        return set_current_fields(\r\n            build_config=build_config,\r\n            action_fields=MODE_FIELDS,\r\n            selected_action=field_value,\r\n            default_fields=DEFAULT_FIELDS,\r\n            func=set_field_advanced,\r\n            default_value=True,\r\n        )\r\n\r\n    async def _response_info(\r\n        self, response: httpx.Response, *, with_file_path: bool = False\r\n    ) -> tuple[bool, Path | None]:\r\n        \"\"\"Determine the file path and whether the response content is binary.\r\n\r\n        Args:\r\n            response (Response): The HTTP response object.\r\n            with_file_path (bool): Whether to save the response content to a file.\r\n\r\n        Returns:\r\n            Tuple[bool, Path | None]:\r\n                A tuple containing a boolean indicating if the content is binary and the full file path (if applicable).\r\n        \"\"\"\r\n        content_type = response.headers.get(\"Content-Type\", \"\")\r\n        is_binary = \"application/octet-stream\" in content_type or \"application/binary\" in content_type\r\n\r\n        if not with_file_path:\r\n            return is_binary, None\r\n\r\n        component_temp_dir = Path(tempfile.gettempdir()) / self.__class__.__name__\r\n\r\n        # Create directory asynchronously\r\n        await aiofiles_os.makedirs(component_temp_dir, exist_ok=True)\r\n\r\n        filename = None\r\n        if \"Content-Disposition\" in response.headers:\r\n            content_disposition = response.headers[\"Content-Disposition\"]\r\n            filename_match = re.search(r'filename=\"(.+?)\"', content_disposition)\r\n            if filename_match:\r\n                extracted_filename = filename_match.group(1)\r\n                filename = extracted_filename\r\n\r\n        # Step 3: Infer file extension or use part of the request URL if no filename\r\n        if not filename:\r\n            # Extract the last segment of the URL path\r\n            url_path = urlparse(str(response.request.url) if response.request else \"\").path\r\n            base_name = Path(url_path).name  # Get the last segment of the path\r\n            if not base_name:  # If the path ends with a slash or is empty\r\n                base_name = \"response\"\r\n\r\n            # Infer file extension\r\n            content_type_to_extension = {\r\n                \"text/plain\": \".txt\",\r\n                \"application/json\": \".json\",\r\n                \"image/jpeg\": \".jpg\",\r\n                \"image/png\": \".png\",\r\n                \"application/octet-stream\": \".bin\",\r\n            }\r\n            extension = content_type_to_extension.get(content_type, \".bin\" if is_binary else \".txt\")\r\n            filename = f\"{base_name}{extension}\"\r\n\r\n        # Step 4: Define the full file path\r\n        file_path = component_temp_dir / filename\r\n\r\n        # Step 5: Check if file exists asynchronously and handle accordingly\r\n        try:\r\n            # Try to create the file exclusively (x mode) to check existence\r\n            async with aiofiles.open(file_path, \"x\") as _:\r\n                pass  # File created successfully, we can use this path\r\n        except FileExistsError:\r\n            # If file exists, append a timestamp to the filename\r\n            timestamp = datetime.now(timezone.utc).strftime(\"%Y%m%d%H%M%S%f\")\r\n            file_path = component_temp_dir / f\"{timestamp}-{filename}\"\r\n\r\n        return is_binary, file_path"
              },
              "curl_input": {
                "_input_type": "MultilineInput",
                "advanced": true,
                "copy_field": false,
                "display_name": "cURL",
                "dynamic": false,
                "info": "Paste a curl command to populate the fields. This will fill in the dictionary fields for headers and body.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "curl_input",
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": false,
                "title_case": false,
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "follow_redirects": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Follow Redirects",
                "dynamic": false,
                "info": "Whether to follow http redirects.",
                "list": false,
                "list_add_label": "Add More",
                "name": "follow_redirects",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "headers": {
                "_input_type": "TableInput",
                "advanced": false,
                "display_name": "Headers",
                "dynamic": false,
                "info": "The headers to send with the request",
                "input_types": [
                  "Data"
                ],
                "is_list": true,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "headers",
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "table_icon": "Table",
                "table_schema": {
                  "columns": [
                    {
                      "default": "None",
                      "description": "Header name",
                      "disable_edit": false,
                      "display_name": "Header",
                      "edit_mode": "popover",
                      "filterable": true,
                      "formatter": "text",
                      "hidden": false,
                      "name": "key",
                      "sortable": true,
                      "type": "str"
                    },
                    {
                      "default": "None",
                      "description": "Header value",
                      "disable_edit": false,
                      "display_name": "Value",
                      "edit_mode": "popover",
                      "filterable": true,
                      "formatter": "text",
                      "hidden": false,
                      "name": "value",
                      "sortable": true,
                      "type": "str"
                    }
                  ]
                },
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "trigger_icon": "Table",
                "trigger_text": "Open table",
                "type": "table",
                "value": [
                  {
                    "key": "Content-Type",
                    "value": "application/json"
                  }
                ]
              },
              "include_httpx_metadata": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Include HTTPx Metadata",
                "dynamic": false,
                "info": "Include properties such as headers, status_code, response_headers, and redirection_history in the output.",
                "list": false,
                "list_add_label": "Add More",
                "name": "include_httpx_metadata",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "method": {
                "_input_type": "DropdownInput",
                "advanced": false,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Method",
                "dynamic": false,
                "info": "The HTTP method to use.",
                "load_from_db": false,
                "name": "method",
                "options": [
                  "GET",
                  "POST",
                  "PATCH",
                  "PUT",
                  "DELETE"
                ],
                "options_metadata": [],
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "POST"
              },
              "mode": {
                "_input_type": "TabInput",
                "advanced": false,
                "display_name": "Mode",
                "dynamic": false,
                "info": "Enable cURL mode to populate fields from a cURL command.",
                "name": "mode",
                "options": [
                  "URL",
                  "cURL"
                ],
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "tab",
                "value": "URL"
              },
              "query_params": {
                "_input_type": "DataInput",
                "advanced": true,
                "display_name": "Query Parameters",
                "dynamic": false,
                "info": "The query parameters to append to the URL.",
                "input_types": [
                  "Data"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "query_params",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "other",
                "value": ""
              },
              "save_to_file": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Save to File",
                "dynamic": false,
                "info": "Save the API response to a temporary file",
                "list": false,
                "list_add_label": "Add More",
                "name": "save_to_file",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "timeout": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Timeout",
                "dynamic": false,
                "info": "The timeout to use for the request.",
                "list": false,
                "list_add_label": "Add More",
                "name": "timeout",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 30
              },
              "url_input": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "URL",
                "dynamic": false,
                "info": "Enter the URL for the request.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "url_input",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "http://localhost:11434/api/generate"
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "APIRequest"
        },
        "dragging": false,
        "id": "APIRequest-OMq9W",
        "measured": {
          "height": 549,
          "width": 320
        },
        "position": {
          "x": -14.352395655327385,
          "y": -855.6186243609521
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "TextOutput-XVyO2",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "category": "input_output",
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Sends text output via API.",
            "display_name": "Text Output",
            "documentation": "https://docs.langflow.org/components-io#text-output",
            "edited": false,
            "field_order": [
              "input_value"
            ],
            "frozen": false,
            "icon": "type",
            "key": "TextOutput",
            "legacy": false,
            "lf_version": "1.5.0",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Output Text",
                "group_outputs": false,
                "method": "text_response",
                "name": "text",
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "score": 0.002151957098264304,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.base.io.text import TextComponent\nfrom langflow.io import MultilineInput, Output\nfrom langflow.schema.message import Message\n\n\nclass TextOutputComponent(TextComponent):\n    display_name = \"Text Output\"\n    description = \"Sends text output via API.\"\n    documentation: str = \"https://docs.langflow.org/components-io#text-output\"\n    icon = \"type\"\n    name = \"TextOutput\"\n\n    inputs = [\n        MultilineInput(\n            name=\"input_value\",\n            display_name=\"Inputs\",\n            info=\"Text to be passed as output.\",\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Output Text\", name=\"text\", method=\"text_response\"),\n    ]\n\n    def text_response(self) -> Message:\n        message = Message(\n            text=self.input_value,\n        )\n        self.status = self.input_value\n        return message\n"
              },
              "input_value": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "copy_field": false,
                "display_name": "Inputs",
                "dynamic": false,
                "info": "Text to be passed as output.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "input_value",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "TextOutput"
        },
        "dragging": false,
        "id": "TextOutput-XVyO2",
        "measured": {
          "height": 201,
          "width": 320
        },
        "position": {
          "x": 105.73741522091723,
          "y": 1152.3957610625648
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "LanguageModelComponent-9qPkX",
          "node": {
            "base_classes": [
              "LanguageModel",
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Runs a language model given a specified provider.",
            "display_name": "Language Model",
            "documentation": "https://docs.langflow.org/components-models",
            "edited": true,
            "field_order": [
              "provider",
              "model_name",
              "api_key",
              "base_url",
              "input_value",
              "system_message",
              "stream",
              "temperature"
            ],
            "frozen": false,
            "icon": "brain-circuit",
            "last_updated": "2025-07-11T18:55:32.844Z",
            "legacy": false,
            "lf_version": "1.5.0",
            "metadata": {
              "keywords": [
                "model",
                "llm",
                "language model",
                "large language model"
              ]
            },
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Model Response",
                "group_outputs": false,
                "hidden": null,
                "method": "text_response",
                "name": "text_output",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Language Model",
                "group_outputs": false,
                "hidden": null,
                "method": "build_model",
                "name": "model_output",
                "options": null,
                "required_inputs": null,
                "selected": "LanguageModel",
                "tool_mode": true,
                "types": [
                  "LanguageModel"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "priority": 0,
            "template": {
              "_type": "Component",
              "api_key": {
                "_input_type": "SecretStrInput",
                "advanced": false,
                "display_name": "No API Key Needed",
                "dynamic": false,
                "info": "Model Provider API key",
                "input_types": [],
                "load_from_db": false,
                "name": "api_key",
                "password": true,
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": false,
                "title_case": false,
                "type": "str",
                "value": ""
              },
              "base_url": {
                "_input_type": "MultilineInput",
                "advanced": true,
                "copy_field": false,
                "display_name": "Ollama Base URL",
                "dynamic": false,
                "info": "Optional: Override Ollama base URL",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "base_url",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "http://localhost:11434"
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from typing import Any\r\n\r\nfrom langchain_anthropic import ChatAnthropic\r\nfrom langchain_google_genai import ChatGoogleGenerativeAI\r\nfrom langchain_openai import ChatOpenAI\r\nfrom langchain_community.chat_models import ChatOllama  # ✅ Ollama import\r\n\r\nfrom langflow.base.models.anthropic_constants import ANTHROPIC_MODELS\r\nfrom langflow.base.models.google_generative_ai_constants import GOOGLE_GENERATIVE_AI_MODELS\r\nfrom langflow.base.models.model import LCModelComponent\r\nfrom langflow.base.models.openai_constants import OPENAI_CHAT_MODEL_NAMES, OPENAI_REASONING_MODEL_NAMES\r\nfrom langflow.field_typing import LanguageModel\r\nfrom langflow.field_typing.range_spec import RangeSpec\r\nfrom langflow.inputs.inputs import BoolInput\r\nfrom langflow.io import DropdownInput, MessageInput, MultilineInput, SecretStrInput, SliderInput\r\nfrom langflow.schema.dotdict import dotdict\r\n\r\n\r\nclass LanguageModelComponent(LCModelComponent):\r\n    display_name = \"Language Model\"\r\n    description = \"Runs a language model given a specified provider.\"\r\n    documentation: str = \"https://docs.langflow.org/components-models\"\r\n    icon = \"brain-circuit\"\r\n    category = \"models\"\r\n    priority = 0  # Set priority to 0 to make it appear first\r\n\r\n    inputs = [\r\n        DropdownInput(\r\n            name=\"provider\",\r\n            display_name=\"Model Provider\",\r\n            options=[\"OpenAI\", \"Anthropic\", \"Google\", \"Ollama\"],\r\n            value=\"OpenAI\",\r\n            info=\"Select the model provider\",\r\n            real_time_refresh=True,\r\n            options_metadata=[\r\n                {\"icon\": \"OpenAI\"},\r\n                {\"icon\": \"Anthropic\"},\r\n                {\"icon\": \"GoogleGenerativeAI\"},\r\n                {\"icon\": \"Bot\"},\r\n            ],\r\n        ),\r\n        DropdownInput(\r\n            name=\"model_name\",\r\n            display_name=\"Model Name\",\r\n            options=OPENAI_CHAT_MODEL_NAMES + OPENAI_REASONING_MODEL_NAMES,\r\n            value=OPENAI_CHAT_MODEL_NAMES[0],\r\n            info=\"Select the model to use\",\r\n            real_time_refresh=True,\r\n        ),\r\n        SecretStrInput(\r\n            name=\"api_key\",\r\n            display_name=\"OpenAI API Key\",\r\n            info=\"Model Provider API key\",\r\n            required=False,\r\n            show=True,\r\n            real_time_refresh=True,\r\n        ),\r\n        MultilineInput(\r\n            name=\"base_url\",\r\n            display_name=\"Ollama Base URL\",\r\n            value=\"http://localhost:11434\",\r\n            info=\"Optional: Override Ollama base URL\",\r\n            advanced=True,\r\n        ),\r\n        MessageInput(\r\n            name=\"input_value\",\r\n            display_name=\"Input\",\r\n            info=\"The input text to send to the model\",\r\n        ),\r\n        MultilineInput(\r\n            name=\"system_message\",\r\n            display_name=\"System Message\",\r\n            info=\"A system message that helps set the behavior of the assistant\",\r\n            advanced=False,\r\n        ),\r\n        BoolInput(\r\n            name=\"stream\",\r\n            display_name=\"Stream\",\r\n            info=\"Whether to stream the response\",\r\n            value=False,\r\n            advanced=True,\r\n        ),\r\n        SliderInput(\r\n            name=\"temperature\",\r\n            display_name=\"Temperature\",\r\n            value=0.1,\r\n            info=\"Controls randomness in responses\",\r\n            range_spec=RangeSpec(min=0, max=1, step=0.01),\r\n            advanced=True,\r\n        ),\r\n    ]\r\n\r\n    def build_model(self) -> LanguageModel:\r\n        provider = self.provider\r\n        model_name = self.model_name\r\n        temperature = self.temperature\r\n        stream = self.stream\r\n\r\n        if provider == \"OpenAI\":\r\n            if not self.api_key:\r\n                msg = \"OpenAI API key is required when using OpenAI provider\"\r\n                raise ValueError(msg)\r\n\r\n            if model_name in OPENAI_REASONING_MODEL_NAMES:\r\n                temperature = None  # Reasoning models don't support temperature\r\n\r\n            return ChatOpenAI(\r\n                model_name=model_name,\r\n                temperature=temperature,\r\n                streaming=stream,\r\n                openai_api_key=self.api_key,\r\n            )\r\n\r\n        if provider == \"Anthropic\":\r\n            if not self.api_key:\r\n                msg = \"Anthropic API key is required when using Anthropic provider\"\r\n                raise ValueError(msg)\r\n            return ChatAnthropic(\r\n                model=model_name,\r\n                temperature=temperature,\r\n                streaming=stream,\r\n                anthropic_api_key=self.api_key,\r\n            )\r\n\r\n        if provider == \"Google\":\r\n            if not self.api_key:\r\n                msg = \"Google API key is required when using Google provider\"\r\n                raise ValueError(msg)\r\n            return ChatGoogleGenerativeAI(\r\n                model=model_name,\r\n                temperature=temperature,\r\n                streaming=stream,\r\n                google_api_key=self.api_key,\r\n            )\r\n\r\n        if provider == \"Ollama\":\r\n            return ChatOllama(\r\n                model=model_name,\r\n                temperature=temperature,\r\n                streaming=stream,\r\n                base_url=self.base_url or \"http://localhost:11434\",\r\n            )\r\n\r\n        raise ValueError(f\"Unknown provider: {provider}\")\r\n\r\n    def update_build_config(self, build_config: dotdict, field_value: Any, field_name: str | None = None) -> dotdict:\r\n        if field_name == \"provider\":\r\n            if field_value == \"OpenAI\":\r\n                build_config[\"model_name\"][\"options\"] = OPENAI_CHAT_MODEL_NAMES + OPENAI_REASONING_MODEL_NAMES\r\n                build_config[\"model_name\"][\"value\"] = OPENAI_CHAT_MODEL_NAMES[0]\r\n                build_config[\"api_key\"][\"display_name\"] = \"OpenAI API Key\"\r\n                build_config[\"api_key\"][\"show\"] = True\r\n            elif field_value == \"Anthropic\":\r\n                build_config[\"model_name\"][\"options\"] = ANTHROPIC_MODELS\r\n                build_config[\"model_name\"][\"value\"] = ANTHROPIC_MODELS[0]\r\n                build_config[\"api_key\"][\"display_name\"] = \"Anthropic API Key\"\r\n                build_config[\"api_key\"][\"show\"] = True\r\n            elif field_value == \"Google\":\r\n                build_config[\"model_name\"][\"options\"] = GOOGLE_GENERATIVE_AI_MODELS\r\n                build_config[\"model_name\"][\"value\"] = GOOGLE_GENERATIVE_AI_MODELS[0]\r\n                build_config[\"api_key\"][\"display_name\"] = \"Google API Key\"\r\n                build_config[\"api_key\"][\"show\"] = True\r\n            elif field_value == \"Ollama\":\r\n                build_config[\"model_name\"][\"options\"] = [\"llama3\", \"mistral\", \"codellama\", \"llama2\"]\r\n                build_config[\"model_name\"][\"value\"] = \"llama3\"\r\n                build_config[\"api_key\"][\"display_name\"] = \"No API Key Needed\"\r\n                build_config[\"api_key\"][\"show\"] = False\r\n        elif field_name == \"model_name\" and field_value.startswith(\"o1\") and self.provider == \"OpenAI\":\r\n            if \"system_message\" in build_config:\r\n                build_config[\"system_message\"][\"show\"] = False\r\n        elif field_name == \"model_name\" and not field_value.startswith(\"o1\") and \"system_message\" in build_config:\r\n            build_config[\"system_message\"][\"show\"] = True\r\n        return build_config\r\n"
              },
              "input_value": {
                "_input_type": "MessageInput",
                "advanced": false,
                "display_name": "Input",
                "dynamic": false,
                "info": "The input text to send to the model",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "input_value",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "model_name": {
                "_input_type": "DropdownInput",
                "advanced": false,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Model Name",
                "dynamic": false,
                "info": "Select the model to use",
                "name": "model_name",
                "options": [
                  "llama3",
                  "mistral",
                  "codellama",
                  "llama2"
                ],
                "options_metadata": [],
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "llama3"
              },
              "provider": {
                "_input_type": "DropdownInput",
                "advanced": false,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Model Provider",
                "dynamic": false,
                "info": "Select the model provider",
                "load_from_db": false,
                "name": "provider",
                "options": [
                  "OpenAI",
                  "Anthropic",
                  "Google",
                  "Ollama"
                ],
                "options_metadata": [
                  {
                    "icon": "OpenAI"
                  },
                  {
                    "icon": "Anthropic"
                  },
                  {
                    "icon": "GoogleGenerativeAI"
                  },
                  {
                    "icon": "Bot"
                  }
                ],
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "Ollama"
              },
              "stream": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Stream",
                "dynamic": false,
                "info": "Whether to stream the response",
                "list": false,
                "list_add_label": "Add More",
                "name": "stream",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "system_message": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "copy_field": false,
                "display_name": "System Message",
                "dynamic": false,
                "info": "A system message that helps set the behavior of the assistant",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "system_message",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "You are a helpful assistant. Provide explanations and short examples where appropriate to make the concept clear."
              },
              "temperature": {
                "_input_type": "SliderInput",
                "advanced": true,
                "display_name": "Temperature",
                "dynamic": false,
                "info": "Controls randomness in responses",
                "max_label": "",
                "max_label_icon": "",
                "min_label": "",
                "min_label_icon": "",
                "name": "temperature",
                "placeholder": "",
                "range_spec": {
                  "max": 1,
                  "min": 0,
                  "step": 0.01,
                  "step_type": "float"
                },
                "required": false,
                "show": true,
                "slider_buttons": false,
                "slider_buttons_options": [],
                "slider_input": false,
                "title_case": false,
                "tool_mode": false,
                "type": "slider",
                "value": 0.1
              }
            },
            "tool_mode": false
          },
          "selected_output": "text_output",
          "showNode": true,
          "type": "LanguageModelComponent"
        },
        "dragging": false,
        "id": "LanguageModelComponent-9qPkX",
        "measured": {
          "height": 447,
          "width": 320
        },
        "position": {
          "x": -470.10316655032227,
          "y": 320.44752385770346
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "CustomComponent-L21Uh",
          "node": {
            "base_classes": [
              "Data"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Use as a template to create your own component.",
            "display_name": "Custom Component",
            "documentation": "https://docs.langflow.org/components-custom-components",
            "edited": true,
            "field_order": [
              "input_value"
            ],
            "frozen": false,
            "icon": "code",
            "legacy": false,
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Output",
                "group_outputs": false,
                "method": "build_output",
                "name": "output",
                "selected": "Data",
                "tool_mode": true,
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "# from langflow.field_typing import Data\nfrom langflow.custom.custom_component.component import Component\nfrom langflow.io import MessageTextInput, Output\nfrom langflow.schema.data import Data\n\n\nclass CustomComponent(Component):\n    display_name = \"Custom Component\"\n    description = \"Use as a template to create your own component.\"\n    documentation: str = \"https://docs.langflow.org/components-custom-components\"\n    icon = \"code\"\n    name = \"CustomComponent\"\n\n    inputs = [\n        MessageTextInput(\n            name=\"input_value\",\n            display_name=\"Input Value\",\n            info=\"This is a custom component Input\",\n            value=\"Hello, World!\",\n            tool_mode=True,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Output\", name=\"output\", method=\"build_output\"),\n    ]\n\n    def build_output(self) -> Data:\n        data = Data(value=self.input_value)\n        self.status = data\n        return data\n"
              },
              "input_value": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Input Value",
                "dynamic": false,
                "info": "This is a custom component Input",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "input_value",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "CustomComponent"
        },
        "dragging": false,
        "id": "CustomComponent-L21Uh",
        "measured": {
          "height": 202,
          "width": 320
        },
        "position": {
          "x": -530.1918725872886,
          "y": -693.0618269935599
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "Prompt Template-65R9W",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {
              "template": [
                "subject",
                "num_questions",
                "difficulty_label",
                "topic"
              ]
            },
            "description": "Create a prompt template with dynamic variables.",
            "display_name": "Prompt Template",
            "documentation": "https://docs.langflow.org/components-prompts",
            "edited": false,
            "error": null,
            "field_order": [
              "template",
              "tool_placeholder"
            ],
            "frozen": false,
            "full_path": null,
            "icon": "braces",
            "is_composition": null,
            "is_input": null,
            "is_output": null,
            "legacy": false,
            "lf_version": "1.5.0",
            "metadata": {},
            "minimized": false,
            "name": "",
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Prompt",
                "group_outputs": false,
                "hidden": null,
                "method": "build_prompt",
                "name": "prompt",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "priority": 0,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.base.prompts.api_utils import process_prompt_template\nfrom langflow.custom.custom_component.component import Component\nfrom langflow.inputs.inputs import DefaultPromptField\nfrom langflow.io import MessageTextInput, Output, PromptInput\nfrom langflow.schema.message import Message\nfrom langflow.template.utils import update_template_values\n\n\nclass PromptComponent(Component):\n    display_name: str = \"Prompt Template\"\n    description: str = \"Create a prompt template with dynamic variables.\"\n    documentation: str = \"https://docs.langflow.org/components-prompts\"\n    icon = \"braces\"\n    trace_type = \"prompt\"\n    name = \"Prompt Template\"\n    priority = 0  # Set priority to 0 to make it appear first\n\n    inputs = [\n        PromptInput(name=\"template\", display_name=\"Template\"),\n        MessageTextInput(\n            name=\"tool_placeholder\",\n            display_name=\"Tool Placeholder\",\n            tool_mode=True,\n            advanced=True,\n            info=\"A placeholder input for tool mode.\",\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Prompt\", name=\"prompt\", method=\"build_prompt\"),\n    ]\n\n    async def build_prompt(self) -> Message:\n        prompt = Message.from_template(**self._attributes)\n        self.status = prompt.text\n        return prompt\n\n    def _update_template(self, frontend_node: dict):\n        prompt_template = frontend_node[\"template\"][\"template\"][\"value\"]\n        custom_fields = frontend_node[\"custom_fields\"]\n        frontend_node_template = frontend_node[\"template\"]\n        _ = process_prompt_template(\n            template=prompt_template,\n            name=\"template\",\n            custom_fields=custom_fields,\n            frontend_node_template=frontend_node_template,\n        )\n        return frontend_node\n\n    async def update_frontend_node(self, new_frontend_node: dict, current_frontend_node: dict):\n        \"\"\"This function is called after the code validation is done.\"\"\"\n        frontend_node = await super().update_frontend_node(new_frontend_node, current_frontend_node)\n        template = frontend_node[\"template\"][\"template\"][\"value\"]\n        # Kept it duplicated for backwards compatibility\n        _ = process_prompt_template(\n            template=template,\n            name=\"template\",\n            custom_fields=frontend_node[\"custom_fields\"],\n            frontend_node_template=frontend_node[\"template\"],\n        )\n        # Now that template is updated, we need to grab any values that were set in the current_frontend_node\n        # and update the frontend_node with those values\n        update_template_values(new_template=frontend_node, previous_template=current_frontend_node[\"template\"])\n        return frontend_node\n\n    def _get_fallback_input(self, **kwargs):\n        return DefaultPromptField(**kwargs)\n"
              },
              "difficulty_label": {
                "advanced": false,
                "display_name": "difficulty_label",
                "dynamic": false,
                "field_type": "str",
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "difficulty_label",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": "easy"
              },
              "num_questions": {
                "advanced": false,
                "display_name": "num_questions",
                "dynamic": false,
                "field_type": "str",
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "num_questions",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": ""
              },
              "subject": {
                "advanced": false,
                "display_name": "subject",
                "dynamic": false,
                "field_type": "str",
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "subject",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": ""
              },
              "template": {
                "_input_type": "PromptInput",
                "advanced": false,
                "display_name": "Template",
                "dynamic": false,
                "info": "",
                "list": false,
                "list_add_label": "Add More",
                "name": "template",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "type": "prompt",
                "value": "You are a question paper generator. Based on the following information, generate a question paper:\n\nSubject: {subject} \nNumber of Questions: {num_questions}\nDifficulty Level: {difficulty_label}\nTopic: {topic}\n"
              },
              "tool_placeholder": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Tool Placeholder",
                "dynamic": false,
                "info": "A placeholder input for tool mode.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "tool_placeholder",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "topic": {
                "advanced": false,
                "display_name": "topic",
                "dynamic": false,
                "field_type": "str",
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "topic",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "Prompt Template"
        },
        "dragging": false,
        "id": "Prompt Template-65R9W",
        "measured": {
          "height": 609,
          "width": 320
        },
        "position": {
          "x": 2783.400018656829,
          "y": 49.18052212736461
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "TextInput-G1fZ4",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "category": "input_output",
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Get user text inputs.",
            "display_name": "Subject",
            "documentation": "https://docs.langflow.org/components-io#text-input",
            "edited": false,
            "field_order": [
              "input_value"
            ],
            "frozen": false,
            "icon": "type",
            "key": "TextInput",
            "legacy": false,
            "lf_version": "1.5.0",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Output Text",
                "group_outputs": false,
                "method": "text_response",
                "name": "text",
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "score": 0.0022704986850629236,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.base.io.text import TextComponent\nfrom langflow.io import MultilineInput, Output\nfrom langflow.schema.message import Message\n\n\nclass TextInputComponent(TextComponent):\n    display_name = \"Text Input\"\n    description = \"Get user text inputs.\"\n    documentation: str = \"https://docs.langflow.org/components-io#text-input\"\n    icon = \"type\"\n    name = \"TextInput\"\n\n    inputs = [\n        MultilineInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            info=\"Text to be passed as input.\",\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Output Text\", name=\"text\", method=\"text_response\"),\n    ]\n\n    def text_response(self) -> Message:\n        return Message(\n            text=self.input_value,\n        )\n"
              },
              "input_value": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "copy_field": false,
                "display_name": "Text",
                "dynamic": false,
                "info": "Text to be passed as input.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "input_value",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "Maths"
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "TextInput"
        },
        "dragging": false,
        "id": "TextInput-G1fZ4",
        "measured": {
          "height": 201,
          "width": 320
        },
        "position": {
          "x": 1843.5321583610812,
          "y": 280.858769981321
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "TextInput-bfqxJ",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Get user text inputs. Only accepts: Easy, Medium, Hard.",
            "display_name": "Difficulty",
            "documentation": "https://docs.langflow.org/components-io#text-input",
            "edited": true,
            "field_order": [
              "input_value"
            ],
            "frozen": false,
            "icon": "type",
            "legacy": false,
            "lf_version": "1.5.0",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Output Text",
                "group_outputs": false,
                "hidden": null,
                "method": "text_response",
                "name": "text",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.base.io.text import TextComponent\r\nfrom langflow.io import MultilineInput, Output\r\nfrom langflow.schema.message import Message\r\n\r\n\r\nclass TextInputComponent(TextComponent):\r\n    display_name = \"Text Input\"\r\n    description = \"Get user text inputs. Only accepts: Easy, Medium, Hard.\"\r\n    documentation: str = \"https://docs.langflow.org/components-io#text-input\"\r\n    icon = \"type\"\r\n    name = \"TextInput\"\r\n\r\n    ALLOWED_OPTIONS = [\"Easy\", \"Medium\", \"Hard\"]  # Dropdown-like options\r\n\r\n    inputs = [\r\n        MultilineInput(\r\n            name=\"input_value\",\r\n            display_name=\"Difficulty Level\",\r\n            info=\"Type only: Easy, Medium, or Hard.\",\r\n        ),\r\n    ]\r\n    outputs = [\r\n        Output(display_name=\"Output Text\", name=\"text\", method=\"text_response\"),\r\n    ]\r\n\r\n    def text_response(self) -> Message:\r\n        if self.input_value not in self.ALLOWED_OPTIONS:\r\n            return Message(\r\n                text=f\"❌ Invalid difficulty. Please enter one of: {', '.join(self.ALLOWED_OPTIONS)}\"\r\n            )\r\n        return Message(\r\n            text=self.input_value,\r\n        )\r\n\r\n"
              },
              "input_value": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "copy_field": false,
                "display_name": "Difficulty Level",
                "dynamic": false,
                "info": "Type only: Easy, Medium, or Hard.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "input_value",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "Hard"
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "TextInput"
        },
        "dragging": false,
        "id": "TextInput-bfqxJ",
        "measured": {
          "height": 217,
          "width": 320
        },
        "position": {
          "x": 1842.0642855986707,
          "y": -226.15117679560876
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "TextInput-1yeOx",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "category": "input_output",
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Get user text inputs.",
            "display_name": "Number of Questions",
            "documentation": "https://docs.langflow.org/components-io#text-input",
            "edited": false,
            "field_order": [
              "input_value"
            ],
            "frozen": false,
            "icon": "type",
            "key": "TextInput",
            "legacy": false,
            "lf_version": "1.5.0",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Output Text",
                "group_outputs": false,
                "method": "text_response",
                "name": "text",
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "score": 0.0022704986850629236,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.base.io.text import TextComponent\nfrom langflow.io import MultilineInput, Output\nfrom langflow.schema.message import Message\n\n\nclass TextInputComponent(TextComponent):\n    display_name = \"Text Input\"\n    description = \"Get user text inputs.\"\n    documentation: str = \"https://docs.langflow.org/components-io#text-input\"\n    icon = \"type\"\n    name = \"TextInput\"\n\n    inputs = [\n        MultilineInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            info=\"Text to be passed as input.\",\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Output Text\", name=\"text\", method=\"text_response\"),\n    ]\n\n    def text_response(self) -> Message:\n        return Message(\n            text=self.input_value,\n        )\n"
              },
              "input_value": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "copy_field": false,
                "display_name": "Text",
                "dynamic": false,
                "info": "Text to be passed as input.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "input_value",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "2"
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "TextInput"
        },
        "dragging": false,
        "id": "TextInput-1yeOx",
        "measured": {
          "height": 201,
          "width": 320
        },
        "position": {
          "x": 1848.241661344534,
          "y": 26.799117193222436
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "TextOutput-Q2X4H",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "category": "input_output",
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Sends text output via API.",
            "display_name": "Feedback",
            "documentation": "https://docs.langflow.org/components-io#text-output",
            "edited": false,
            "field_order": [
              "input_value"
            ],
            "frozen": false,
            "icon": "type",
            "key": "TextOutput",
            "legacy": false,
            "lf_version": "1.5.0",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Output Text",
                "group_outputs": false,
                "method": "text_response",
                "name": "text",
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "score": 0.002151957098264304,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.base.io.text import TextComponent\nfrom langflow.io import MultilineInput, Output\nfrom langflow.schema.message import Message\n\n\nclass TextOutputComponent(TextComponent):\n    display_name = \"Text Output\"\n    description = \"Sends text output via API.\"\n    documentation: str = \"https://docs.langflow.org/components-io#text-output\"\n    icon = \"type\"\n    name = \"TextOutput\"\n\n    inputs = [\n        MultilineInput(\n            name=\"input_value\",\n            display_name=\"Inputs\",\n            info=\"Text to be passed as output.\",\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Output Text\", name=\"text\", method=\"text_response\"),\n    ]\n\n    def text_response(self) -> Message:\n        message = Message(\n            text=self.input_value,\n        )\n        self.status = self.input_value\n        return message\n"
              },
              "input_value": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "copy_field": false,
                "display_name": "Inputs",
                "dynamic": false,
                "info": "Text to be passed as output.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "input_value",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "TextOutput"
        },
        "dragging": false,
        "id": "TextOutput-Q2X4H",
        "measured": {
          "height": 201,
          "width": 320
        },
        "position": {
          "x": 4640.928848703254,
          "y": 866.1924069356596
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "Prompt Template-fmpvn",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {
              "template": [
                "question_output",
                "feedback",
                "subject",
                "topic",
                "difficulty",
                "num_questions"
              ]
            },
            "description": "Create a prompt template with dynamic variables.",
            "display_name": "Prompt Template",
            "documentation": "https://docs.langflow.org/components-prompts",
            "edited": false,
            "error": null,
            "field_order": [
              "template",
              "tool_placeholder"
            ],
            "frozen": false,
            "full_path": null,
            "icon": "braces",
            "is_composition": null,
            "is_input": null,
            "is_output": null,
            "legacy": false,
            "metadata": {},
            "minimized": false,
            "name": "",
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Prompt",
                "group_outputs": false,
                "hidden": null,
                "method": "build_prompt",
                "name": "prompt",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "priority": 0,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.base.prompts.api_utils import process_prompt_template\nfrom langflow.custom.custom_component.component import Component\nfrom langflow.inputs.inputs import DefaultPromptField\nfrom langflow.io import MessageTextInput, Output, PromptInput\nfrom langflow.schema.message import Message\nfrom langflow.template.utils import update_template_values\n\n\nclass PromptComponent(Component):\n    display_name: str = \"Prompt Template\"\n    description: str = \"Create a prompt template with dynamic variables.\"\n    documentation: str = \"https://docs.langflow.org/components-prompts\"\n    icon = \"braces\"\n    trace_type = \"prompt\"\n    name = \"Prompt Template\"\n    priority = 0  # Set priority to 0 to make it appear first\n\n    inputs = [\n        PromptInput(name=\"template\", display_name=\"Template\"),\n        MessageTextInput(\n            name=\"tool_placeholder\",\n            display_name=\"Tool Placeholder\",\n            tool_mode=True,\n            advanced=True,\n            info=\"A placeholder input for tool mode.\",\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Prompt\", name=\"prompt\", method=\"build_prompt\"),\n    ]\n\n    async def build_prompt(self) -> Message:\n        prompt = Message.from_template(**self._attributes)\n        self.status = prompt.text\n        return prompt\n\n    def _update_template(self, frontend_node: dict):\n        prompt_template = frontend_node[\"template\"][\"template\"][\"value\"]\n        custom_fields = frontend_node[\"custom_fields\"]\n        frontend_node_template = frontend_node[\"template\"]\n        _ = process_prompt_template(\n            template=prompt_template,\n            name=\"template\",\n            custom_fields=custom_fields,\n            frontend_node_template=frontend_node_template,\n        )\n        return frontend_node\n\n    async def update_frontend_node(self, new_frontend_node: dict, current_frontend_node: dict):\n        \"\"\"This function is called after the code validation is done.\"\"\"\n        frontend_node = await super().update_frontend_node(new_frontend_node, current_frontend_node)\n        template = frontend_node[\"template\"][\"template\"][\"value\"]\n        # Kept it duplicated for backwards compatibility\n        _ = process_prompt_template(\n            template=template,\n            name=\"template\",\n            custom_fields=frontend_node[\"custom_fields\"],\n            frontend_node_template=frontend_node[\"template\"],\n        )\n        # Now that template is updated, we need to grab any values that were set in the current_frontend_node\n        # and update the frontend_node with those values\n        update_template_values(new_template=frontend_node, previous_template=current_frontend_node[\"template\"])\n        return frontend_node\n\n    def _get_fallback_input(self, **kwargs):\n        return DefaultPromptField(**kwargs)\n"
              },
              "difficulty": {
                "advanced": false,
                "display_name": "difficulty",
                "dynamic": false,
                "field_type": "str",
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "difficulty",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": ""
              },
              "feedback": {
                "advanced": false,
                "display_name": "feedback",
                "dynamic": false,
                "field_type": "str",
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "feedback",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": ""
              },
              "num_questions": {
                "advanced": false,
                "display_name": "num_questions",
                "dynamic": false,
                "field_type": "str",
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "num_questions",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": ""
              },
              "question_output": {
                "advanced": false,
                "display_name": "question_output",
                "dynamic": false,
                "field_type": "str",
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "question_output",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": ""
              },
              "subject": {
                "advanced": false,
                "display_name": "subject",
                "dynamic": false,
                "field_type": "str",
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "subject",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": ""
              },
              "template": {
                "_input_type": "PromptInput",
                "advanced": false,
                "display_name": "Template",
                "dynamic": false,
                "info": "",
                "list": false,
                "list_add_label": "Add More",
                "name": "template",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "type": "prompt",
                "value": "You are an expert in question paper generation.\n\nHere is the question paper generated:\n{question_output}\n\nThe student’s feedback for the above was:\n{feedback}\n\nPlease improve the question paper based on this feedback, keeping the format, subject ({subject}), topic ({topic}), difficulty ({difficulty}), and number of questions ({num_questions}) the same.\n\n\n\n"
              },
              "tool_placeholder": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Tool Placeholder",
                "dynamic": false,
                "info": "A placeholder input for tool mode.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "tool_placeholder",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "topic": {
                "advanced": false,
                "display_name": "topic",
                "dynamic": false,
                "field_type": "str",
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "topic",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "Prompt Template"
        },
        "dragging": false,
        "id": "Prompt Template-fmpvn",
        "measured": {
          "height": 772,
          "width": 320
        },
        "position": {
          "x": 5587.773287216463,
          "y": 74.43866487677585
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "TextOutput-fsKDZ",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "category": "input_output",
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Sends text output via API.",
            "display_name": "Question Paper",
            "documentation": "https://docs.langflow.org/components-io#text-output",
            "edited": false,
            "field_order": [
              "input_value"
            ],
            "frozen": false,
            "icon": "type",
            "key": "TextOutput",
            "legacy": false,
            "lf_version": "1.5.0",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Output Text",
                "group_outputs": false,
                "method": "text_response",
                "name": "text",
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "score": 0.0026904540161865127,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.base.io.text import TextComponent\nfrom langflow.io import MultilineInput, Output\nfrom langflow.schema.message import Message\n\n\nclass TextOutputComponent(TextComponent):\n    display_name = \"Text Output\"\n    description = \"Sends text output via API.\"\n    documentation: str = \"https://docs.langflow.org/components-io#text-output\"\n    icon = \"type\"\n    name = \"TextOutput\"\n\n    inputs = [\n        MultilineInput(\n            name=\"input_value\",\n            display_name=\"Inputs\",\n            info=\"Text to be passed as output.\",\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Output Text\", name=\"text\", method=\"text_response\"),\n    ]\n\n    def text_response(self) -> Message:\n        message = Message(\n            text=self.input_value,\n        )\n        self.status = self.input_value\n        return message\n"
              },
              "input_value": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "copy_field": false,
                "display_name": "Inputs",
                "dynamic": false,
                "info": "Text to be passed as output.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "input_value",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "TextOutput"
        },
        "dragging": false,
        "id": "TextOutput-fsKDZ",
        "measured": {
          "height": 201,
          "width": 320
        },
        "position": {
          "x": 4157.358917984869,
          "y": 427.4993361036492
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "LanguageModelComponent-jQOdc",
          "node": {
            "base_classes": [
              "LanguageModel",
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Runs a language model given a specified provider.",
            "display_name": "Language Model",
            "documentation": "https://docs.langflow.org/components-models",
            "edited": true,
            "field_order": [
              "provider",
              "model_name",
              "api_key",
              "base_url",
              "input_value",
              "system_message",
              "stream",
              "temperature"
            ],
            "frozen": false,
            "icon": "brain-circuit",
            "last_updated": "2025-07-14T07:11:47.354Z",
            "legacy": false,
            "lf_version": "1.5.0",
            "metadata": {
              "keywords": [
                "model",
                "llm",
                "language model",
                "large language model"
              ]
            },
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Model Response",
                "group_outputs": false,
                "hidden": null,
                "method": "text_response",
                "name": "text_output",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Language Model",
                "group_outputs": false,
                "hidden": null,
                "method": "build_model",
                "name": "model_output",
                "options": null,
                "required_inputs": null,
                "selected": "LanguageModel",
                "tool_mode": true,
                "types": [
                  "LanguageModel"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "priority": 0,
            "template": {
              "_type": "Component",
              "api_key": {
                "_input_type": "SecretStrInput",
                "advanced": false,
                "display_name": "No API Key Needed",
                "dynamic": false,
                "info": "Model Provider API key",
                "input_types": [],
                "load_from_db": false,
                "name": "api_key",
                "password": true,
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": false,
                "title_case": false,
                "type": "str",
                "value": ""
              },
              "base_url": {
                "_input_type": "MultilineInput",
                "advanced": true,
                "copy_field": false,
                "display_name": "Ollama Base URL",
                "dynamic": false,
                "info": "Optional: Override Ollama base URL",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "base_url",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "http://localhost:11434"
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from typing import Any\r\n\r\nfrom langchain_anthropic import ChatAnthropic\r\nfrom langchain_google_genai import ChatGoogleGenerativeAI\r\nfrom langchain_openai import ChatOpenAI\r\nfrom langchain_community.chat_models import ChatOllama  # ✅ Ollama import\r\n\r\nfrom langflow.base.models.anthropic_constants import ANTHROPIC_MODELS\r\nfrom langflow.base.models.google_generative_ai_constants import GOOGLE_GENERATIVE_AI_MODELS\r\nfrom langflow.base.models.model import LCModelComponent\r\nfrom langflow.base.models.openai_constants import OPENAI_CHAT_MODEL_NAMES, OPENAI_REASONING_MODEL_NAMES\r\nfrom langflow.field_typing import LanguageModel\r\nfrom langflow.field_typing.range_spec import RangeSpec\r\nfrom langflow.inputs.inputs import BoolInput\r\nfrom langflow.io import DropdownInput, MessageInput, MultilineInput, SecretStrInput, SliderInput\r\nfrom langflow.schema.dotdict import dotdict\r\n\r\n\r\nclass LanguageModelComponent(LCModelComponent):\r\n    display_name = \"Language Model\"\r\n    description = \"Runs a language model given a specified provider.\"\r\n    documentation: str = \"https://docs.langflow.org/components-models\"\r\n    icon = \"brain-circuit\"\r\n    category = \"models\"\r\n    priority = 0  # Set priority to 0 to make it appear first\r\n\r\n    inputs = [\r\n        DropdownInput(\r\n            name=\"provider\",\r\n            display_name=\"Model Provider\",\r\n            options=[\"OpenAI\", \"Anthropic\", \"Google\", \"Ollama\"],\r\n            value=\"OpenAI\",\r\n            info=\"Select the model provider\",\r\n            real_time_refresh=True,\r\n            options_metadata=[\r\n                {\"icon\": \"OpenAI\"},\r\n                {\"icon\": \"Anthropic\"},\r\n                {\"icon\": \"GoogleGenerativeAI\"},\r\n                {\"icon\": \"Bot\"},\r\n            ],\r\n        ),\r\n        DropdownInput(\r\n            name=\"model_name\",\r\n            display_name=\"Model Name\",\r\n            options=OPENAI_CHAT_MODEL_NAMES + OPENAI_REASONING_MODEL_NAMES,\r\n            value=OPENAI_CHAT_MODEL_NAMES[0],\r\n            info=\"Select the model to use\",\r\n            real_time_refresh=True,\r\n        ),\r\n        SecretStrInput(\r\n            name=\"api_key\",\r\n            display_name=\"OpenAI API Key\",\r\n            info=\"Model Provider API key\",\r\n            required=False,\r\n            show=True,\r\n            real_time_refresh=True,\r\n        ),\r\n        MultilineInput(\r\n            name=\"base_url\",\r\n            display_name=\"Ollama Base URL\",\r\n            value=\"http://localhost:11434\",\r\n            info=\"Optional: Override Ollama base URL\",\r\n            advanced=True,\r\n        ),\r\n        MessageInput(\r\n            name=\"input_value\",\r\n            display_name=\"Input\",\r\n            info=\"The input text to send to the model\",\r\n        ),\r\n        MultilineInput(\r\n            name=\"system_message\",\r\n            display_name=\"System Message\",\r\n            info=\"A system message that helps set the behavior of the assistant\",\r\n            advanced=False,\r\n        ),\r\n        BoolInput(\r\n            name=\"stream\",\r\n            display_name=\"Stream\",\r\n            info=\"Whether to stream the response\",\r\n            value=False,\r\n            advanced=True,\r\n        ),\r\n        SliderInput(\r\n            name=\"temperature\",\r\n            display_name=\"Temperature\",\r\n            value=0.1,\r\n            info=\"Controls randomness in responses\",\r\n            range_spec=RangeSpec(min=0, max=1, step=0.01),\r\n            advanced=True,\r\n        ),\r\n    ]\r\n\r\n    def build_model(self) -> LanguageModel:\r\n        provider = self.provider\r\n        model_name = self.model_name\r\n        temperature = self.temperature\r\n        stream = self.stream\r\n\r\n        if provider == \"OpenAI\":\r\n            if not self.api_key:\r\n                msg = \"OpenAI API key is required when using OpenAI provider\"\r\n                raise ValueError(msg)\r\n\r\n            if model_name in OPENAI_REASONING_MODEL_NAMES:\r\n                temperature = None  # Reasoning models don't support temperature\r\n\r\n            return ChatOpenAI(\r\n                model_name=model_name,\r\n                temperature=temperature,\r\n                streaming=stream,\r\n                openai_api_key=self.api_key,\r\n            )\r\n\r\n        if provider == \"Anthropic\":\r\n            if not self.api_key:\r\n                msg = \"Anthropic API key is required when using Anthropic provider\"\r\n                raise ValueError(msg)\r\n            return ChatAnthropic(\r\n                model=model_name,\r\n                temperature=temperature,\r\n                streaming=stream,\r\n                anthropic_api_key=self.api_key,\r\n            )\r\n\r\n        if provider == \"Google\":\r\n            if not self.api_key:\r\n                msg = \"Google API key is required when using Google provider\"\r\n                raise ValueError(msg)\r\n            return ChatGoogleGenerativeAI(\r\n                model=model_name,\r\n                temperature=temperature,\r\n                streaming=stream,\r\n                google_api_key=self.api_key,\r\n            )\r\n\r\n        if provider == \"Ollama\":\r\n            return ChatOllama(\r\n                model=model_name,\r\n                temperature=temperature,\r\n                streaming=stream,\r\n                base_url=self.base_url or \"http://localhost:11434\",\r\n            )\r\n\r\n        raise ValueError(f\"Unknown provider: {provider}\")\r\n\r\n    def update_build_config(self, build_config: dotdict, field_value: Any, field_name: str | None = None) -> dotdict:\r\n        if field_name == \"provider\":\r\n            if field_value == \"OpenAI\":\r\n                build_config[\"model_name\"][\"options\"] = OPENAI_CHAT_MODEL_NAMES + OPENAI_REASONING_MODEL_NAMES\r\n                build_config[\"model_name\"][\"value\"] = OPENAI_CHAT_MODEL_NAMES[0]\r\n                build_config[\"api_key\"][\"display_name\"] = \"OpenAI API Key\"\r\n                build_config[\"api_key\"][\"show\"] = True\r\n            elif field_value == \"Anthropic\":\r\n                build_config[\"model_name\"][\"options\"] = ANTHROPIC_MODELS\r\n                build_config[\"model_name\"][\"value\"] = ANTHROPIC_MODELS[0]\r\n                build_config[\"api_key\"][\"display_name\"] = \"Anthropic API Key\"\r\n                build_config[\"api_key\"][\"show\"] = True\r\n            elif field_value == \"Google\":\r\n                build_config[\"model_name\"][\"options\"] = GOOGLE_GENERATIVE_AI_MODELS\r\n                build_config[\"model_name\"][\"value\"] = GOOGLE_GENERATIVE_AI_MODELS[0]\r\n                build_config[\"api_key\"][\"display_name\"] = \"Google API Key\"\r\n                build_config[\"api_key\"][\"show\"] = True\r\n            elif field_value == \"Ollama\":\r\n                build_config[\"model_name\"][\"options\"] = [\"llama3\", \"mistral\", \"codellama\", \"llama2\"]\r\n                build_config[\"model_name\"][\"value\"] = \"llama3\"\r\n                build_config[\"api_key\"][\"display_name\"] = \"No API Key Needed\"\r\n                build_config[\"api_key\"][\"show\"] = False\r\n        elif field_name == \"model_name\" and field_value.startswith(\"o1\") and self.provider == \"OpenAI\":\r\n            if \"system_message\" in build_config:\r\n                build_config[\"system_message\"][\"show\"] = False\r\n        elif field_name == \"model_name\" and not field_value.startswith(\"o1\") and \"system_message\" in build_config:\r\n            build_config[\"system_message\"][\"show\"] = True\r\n        return build_config\r\n"
              },
              "input_value": {
                "_input_type": "MessageInput",
                "advanced": false,
                "display_name": "Input",
                "dynamic": false,
                "info": "The input text to send to the model",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "input_value",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "model_name": {
                "_input_type": "DropdownInput",
                "advanced": false,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Model Name",
                "dynamic": false,
                "info": "Select the model to use",
                "name": "model_name",
                "options": [
                  "llama3",
                  "mistral",
                  "codellama",
                  "llama2"
                ],
                "options_metadata": [],
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "llama3"
              },
              "provider": {
                "_input_type": "DropdownInput",
                "advanced": false,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Model Provider",
                "dynamic": false,
                "info": "Select the model provider",
                "name": "provider",
                "options": [
                  "OpenAI",
                  "Anthropic",
                  "Google",
                  "Ollama"
                ],
                "options_metadata": [
                  {
                    "icon": "OpenAI"
                  },
                  {
                    "icon": "Anthropic"
                  },
                  {
                    "icon": "GoogleGenerativeAI"
                  },
                  {
                    "icon": "Bot"
                  }
                ],
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "Ollama"
              },
              "stream": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Stream",
                "dynamic": false,
                "info": "Whether to stream the response",
                "list": false,
                "list_add_label": "Add More",
                "name": "stream",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "system_message": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "copy_field": false,
                "display_name": "System Message",
                "dynamic": false,
                "info": "A system message that helps set the behavior of the assistant",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "system_message",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "temperature": {
                "_input_type": "SliderInput",
                "advanced": true,
                "display_name": "Temperature",
                "dynamic": false,
                "info": "Controls randomness in responses",
                "max_label": "",
                "max_label_icon": "",
                "min_label": "",
                "min_label_icon": "",
                "name": "temperature",
                "placeholder": "",
                "range_spec": {
                  "max": 1,
                  "min": 0,
                  "step": 0.01,
                  "step_type": "float"
                },
                "required": false,
                "show": true,
                "slider_buttons": false,
                "slider_buttons_options": [],
                "slider_input": false,
                "title_case": false,
                "tool_mode": false,
                "type": "slider",
                "value": 0.1
              }
            },
            "tool_mode": false
          },
          "selected_output": "text_output",
          "showNode": true,
          "type": "LanguageModelComponent"
        },
        "dragging": false,
        "id": "LanguageModelComponent-jQOdc",
        "measured": {
          "height": 447,
          "width": 320
        },
        "position": {
          "x": 3552.14996868925,
          "y": 291.4640492415186
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "TextInput-ZFx6E",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Get user text inputs.",
            "display_name": "Topic",
            "documentation": "https://docs.langflow.org/components-io#text-input",
            "edited": false,
            "field_order": [
              "input_value"
            ],
            "frozen": false,
            "icon": "type",
            "legacy": false,
            "lf_version": "1.5.0",
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Output Text",
                "group_outputs": false,
                "method": "text_response",
                "name": "text",
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.base.io.text import TextComponent\nfrom langflow.io import MultilineInput, Output\nfrom langflow.schema.message import Message\n\n\nclass TextInputComponent(TextComponent):\n    display_name = \"Text Input\"\n    description = \"Get user text inputs.\"\n    documentation: str = \"https://docs.langflow.org/components-io#text-input\"\n    icon = \"type\"\n    name = \"TextInput\"\n\n    inputs = [\n        MultilineInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            info=\"Text to be passed as input.\",\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Output Text\", name=\"text\", method=\"text_response\"),\n    ]\n\n    def text_response(self) -> Message:\n        return Message(\n            text=self.input_value,\n        )\n"
              },
              "input_value": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "copy_field": false,
                "display_name": "Text",
                "dynamic": false,
                "info": "Text to be passed as input.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "input_value",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "Profit and Loss"
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "TextInput"
        },
        "dragging": false,
        "id": "TextInput-ZFx6E",
        "measured": {
          "height": 201,
          "width": 320
        },
        "position": {
          "x": 1837.0051886282956,
          "y": 571.0048303746526
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "LanguageModelComponent-k4nuc",
          "node": {
            "base_classes": [
              "LanguageModel",
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Runs a language model given a specified provider.",
            "display_name": "Language Model",
            "documentation": "https://docs.langflow.org/components-models",
            "edited": true,
            "field_order": [
              "provider",
              "model_name",
              "api_key",
              "base_url",
              "input_value",
              "system_message",
              "stream",
              "temperature"
            ],
            "frozen": false,
            "icon": "brain-circuit",
            "last_updated": "2025-07-22T18:23:28.107Z",
            "legacy": false,
            "metadata": {
              "keywords": [
                "model",
                "llm",
                "language model",
                "large language model"
              ]
            },
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Model Response",
                "group_outputs": false,
                "hidden": null,
                "method": "text_response",
                "name": "text_output",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Language Model",
                "group_outputs": false,
                "hidden": null,
                "method": "build_model",
                "name": "model_output",
                "options": null,
                "required_inputs": null,
                "selected": "LanguageModel",
                "tool_mode": true,
                "types": [
                  "LanguageModel"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "priority": 0,
            "template": {
              "_type": "Component",
              "api_key": {
                "_input_type": "SecretStrInput",
                "advanced": false,
                "display_name": "No API Key Needed",
                "dynamic": false,
                "info": "Model Provider API key",
                "input_types": [],
                "load_from_db": false,
                "name": "api_key",
                "password": true,
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": false,
                "title_case": false,
                "type": "str",
                "value": ""
              },
              "base_url": {
                "_input_type": "MultilineInput",
                "advanced": true,
                "copy_field": false,
                "display_name": "Ollama Base URL",
                "dynamic": false,
                "info": "Optional: Override Ollama base URL",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "base_url",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "http://localhost:11434"
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from typing import Any\r\n\r\nfrom langchain_anthropic import ChatAnthropic\r\nfrom langchain_google_genai import ChatGoogleGenerativeAI\r\nfrom langchain_openai import ChatOpenAI\r\nfrom langchain_community.chat_models import ChatOllama  # ✅ Ollama import\r\n\r\nfrom langflow.base.models.anthropic_constants import ANTHROPIC_MODELS\r\nfrom langflow.base.models.google_generative_ai_constants import GOOGLE_GENERATIVE_AI_MODELS\r\nfrom langflow.base.models.model import LCModelComponent\r\nfrom langflow.base.models.openai_constants import OPENAI_CHAT_MODEL_NAMES, OPENAI_REASONING_MODEL_NAMES\r\nfrom langflow.field_typing import LanguageModel\r\nfrom langflow.field_typing.range_spec import RangeSpec\r\nfrom langflow.inputs.inputs import BoolInput\r\nfrom langflow.io import DropdownInput, MessageInput, MultilineInput, SecretStrInput, SliderInput\r\nfrom langflow.schema.dotdict import dotdict\r\n\r\n\r\nclass LanguageModelComponent(LCModelComponent):\r\n    display_name = \"Language Model\"\r\n    description = \"Runs a language model given a specified provider.\"\r\n    documentation: str = \"https://docs.langflow.org/components-models\"\r\n    icon = \"brain-circuit\"\r\n    category = \"models\"\r\n    priority = 0  # Set priority to 0 to make it appear first\r\n\r\n    inputs = [\r\n        DropdownInput(\r\n            name=\"provider\",\r\n            display_name=\"Model Provider\",\r\n            options=[\"OpenAI\", \"Anthropic\", \"Google\", \"Ollama\"],\r\n            value=\"OpenAI\",\r\n            info=\"Select the model provider\",\r\n            real_time_refresh=True,\r\n            options_metadata=[\r\n                {\"icon\": \"OpenAI\"},\r\n                {\"icon\": \"Anthropic\"},\r\n                {\"icon\": \"GoogleGenerativeAI\"},\r\n                {\"icon\": \"Bot\"},\r\n            ],\r\n        ),\r\n        DropdownInput(\r\n            name=\"model_name\",\r\n            display_name=\"Model Name\",\r\n            options=OPENAI_CHAT_MODEL_NAMES + OPENAI_REASONING_MODEL_NAMES,\r\n            value=OPENAI_CHAT_MODEL_NAMES[0],\r\n            info=\"Select the model to use\",\r\n            real_time_refresh=True,\r\n        ),\r\n        SecretStrInput(\r\n            name=\"api_key\",\r\n            display_name=\"OpenAI API Key\",\r\n            info=\"Model Provider API key\",\r\n            required=False,\r\n            show=True,\r\n            real_time_refresh=True,\r\n        ),\r\n        MultilineInput(\r\n            name=\"base_url\",\r\n            display_name=\"Ollama Base URL\",\r\n            value=\"http://localhost:11434\",\r\n            info=\"Optional: Override Ollama base URL\",\r\n            advanced=True,\r\n        ),\r\n        MessageInput(\r\n            name=\"input_value\",\r\n            display_name=\"Input\",\r\n            info=\"The input text to send to the model\",\r\n        ),\r\n        MultilineInput(\r\n            name=\"system_message\",\r\n            display_name=\"System Message\",\r\n            info=\"A system message that helps set the behavior of the assistant\",\r\n            advanced=False,\r\n        ),\r\n        BoolInput(\r\n            name=\"stream\",\r\n            display_name=\"Stream\",\r\n            info=\"Whether to stream the response\",\r\n            value=False,\r\n            advanced=True,\r\n        ),\r\n        SliderInput(\r\n            name=\"temperature\",\r\n            display_name=\"Temperature\",\r\n            value=0.1,\r\n            info=\"Controls randomness in responses\",\r\n            range_spec=RangeSpec(min=0, max=1, step=0.01),\r\n            advanced=True,\r\n        ),\r\n    ]\r\n\r\n    def build_model(self) -> LanguageModel:\r\n        provider = self.provider\r\n        model_name = self.model_name\r\n        temperature = self.temperature\r\n        stream = self.stream\r\n\r\n        if provider == \"OpenAI\":\r\n            if not self.api_key:\r\n                msg = \"OpenAI API key is required when using OpenAI provider\"\r\n                raise ValueError(msg)\r\n\r\n            if model_name in OPENAI_REASONING_MODEL_NAMES:\r\n                temperature = None  # Reasoning models don't support temperature\r\n\r\n            return ChatOpenAI(\r\n                model_name=model_name,\r\n                temperature=temperature,\r\n                streaming=stream,\r\n                openai_api_key=self.api_key,\r\n            )\r\n\r\n        if provider == \"Anthropic\":\r\n            if not self.api_key:\r\n                msg = \"Anthropic API key is required when using Anthropic provider\"\r\n                raise ValueError(msg)\r\n            return ChatAnthropic(\r\n                model=model_name,\r\n                temperature=temperature,\r\n                streaming=stream,\r\n                anthropic_api_key=self.api_key,\r\n            )\r\n\r\n        if provider == \"Google\":\r\n            if not self.api_key:\r\n                msg = \"Google API key is required when using Google provider\"\r\n                raise ValueError(msg)\r\n            return ChatGoogleGenerativeAI(\r\n                model=model_name,\r\n                temperature=temperature,\r\n                streaming=stream,\r\n                google_api_key=self.api_key,\r\n            )\r\n\r\n        if provider == \"Ollama\":\r\n            return ChatOllama(\r\n                model=model_name,\r\n                temperature=temperature,\r\n                streaming=stream,\r\n                base_url=self.base_url or \"http://localhost:11434\",\r\n            )\r\n\r\n        raise ValueError(f\"Unknown provider: {provider}\")\r\n\r\n    def update_build_config(self, build_config: dotdict, field_value: Any, field_name: str | None = None) -> dotdict:\r\n        if field_name == \"provider\":\r\n            if field_value == \"OpenAI\":\r\n                build_config[\"model_name\"][\"options\"] = OPENAI_CHAT_MODEL_NAMES + OPENAI_REASONING_MODEL_NAMES\r\n                build_config[\"model_name\"][\"value\"] = OPENAI_CHAT_MODEL_NAMES[0]\r\n                build_config[\"api_key\"][\"display_name\"] = \"OpenAI API Key\"\r\n                build_config[\"api_key\"][\"show\"] = True\r\n            elif field_value == \"Anthropic\":\r\n                build_config[\"model_name\"][\"options\"] = ANTHROPIC_MODELS\r\n                build_config[\"model_name\"][\"value\"] = ANTHROPIC_MODELS[0]\r\n                build_config[\"api_key\"][\"display_name\"] = \"Anthropic API Key\"\r\n                build_config[\"api_key\"][\"show\"] = True\r\n            elif field_value == \"Google\":\r\n                build_config[\"model_name\"][\"options\"] = GOOGLE_GENERATIVE_AI_MODELS\r\n                build_config[\"model_name\"][\"value\"] = GOOGLE_GENERATIVE_AI_MODELS[0]\r\n                build_config[\"api_key\"][\"display_name\"] = \"Google API Key\"\r\n                build_config[\"api_key\"][\"show\"] = True\r\n            elif field_value == \"Ollama\":\r\n                build_config[\"model_name\"][\"options\"] = [\"llama3\", \"mistral\", \"codellama\", \"llama2\"]\r\n                build_config[\"model_name\"][\"value\"] = \"llama3\"\r\n                build_config[\"api_key\"][\"display_name\"] = \"No API Key Needed\"\r\n                build_config[\"api_key\"][\"show\"] = False\r\n        elif field_name == \"model_name\" and field_value.startswith(\"o1\") and self.provider == \"OpenAI\":\r\n            if \"system_message\" in build_config:\r\n                build_config[\"system_message\"][\"show\"] = False\r\n        elif field_name == \"model_name\" and not field_value.startswith(\"o1\") and \"system_message\" in build_config:\r\n            build_config[\"system_message\"][\"show\"] = True\r\n        return build_config\r\n"
              },
              "input_value": {
                "_input_type": "MessageInput",
                "advanced": false,
                "display_name": "Input",
                "dynamic": false,
                "info": "The input text to send to the model",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "input_value",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "model_name": {
                "_input_type": "DropdownInput",
                "advanced": false,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Model Name",
                "dynamic": false,
                "info": "Select the model to use",
                "name": "model_name",
                "options": [
                  "llama3",
                  "mistral",
                  "codellama",
                  "llama2"
                ],
                "options_metadata": [],
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "llama3"
              },
              "provider": {
                "_input_type": "DropdownInput",
                "advanced": false,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Model Provider",
                "dynamic": false,
                "info": "Select the model provider",
                "name": "provider",
                "options": [
                  "OpenAI",
                  "Anthropic",
                  "Google",
                  "Ollama"
                ],
                "options_metadata": [
                  {
                    "icon": "OpenAI"
                  },
                  {
                    "icon": "Anthropic"
                  },
                  {
                    "icon": "GoogleGenerativeAI"
                  },
                  {
                    "icon": "Bot"
                  }
                ],
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "Ollama"
              },
              "stream": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Stream",
                "dynamic": false,
                "info": "Whether to stream the response",
                "list": false,
                "list_add_label": "Add More",
                "name": "stream",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "system_message": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "copy_field": false,
                "display_name": "System Message",
                "dynamic": false,
                "info": "A system message that helps set the behavior of the assistant",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "system_message",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "temperature": {
                "_input_type": "SliderInput",
                "advanced": true,
                "display_name": "Temperature",
                "dynamic": false,
                "info": "Controls randomness in responses",
                "max_label": "",
                "max_label_icon": "",
                "min_label": "",
                "min_label_icon": "",
                "name": "temperature",
                "placeholder": "",
                "range_spec": {
                  "max": 1,
                  "min": 0,
                  "step": 0.01,
                  "step_type": "float"
                },
                "required": false,
                "show": true,
                "slider_buttons": false,
                "slider_buttons_options": [],
                "slider_input": false,
                "title_case": false,
                "tool_mode": false,
                "type": "slider",
                "value": 0.1
              }
            },
            "tool_mode": false
          },
          "selected_output": "text_output",
          "showNode": true,
          "type": "LanguageModelComponent"
        },
        "dragging": false,
        "id": "LanguageModelComponent-k4nuc",
        "measured": {
          "height": 447,
          "width": 320
        },
        "position": {
          "x": 6183.291710741547,
          "y": 634.3930607951521
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "ChatInput-OENj0",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "category": "input_output",
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Get chat inputs from the Playground.",
            "display_name": "Chat Input",
            "documentation": "https://docs.langflow.org/components-io#chat-input",
            "edited": false,
            "field_order": [
              "input_value",
              "should_store_message",
              "sender",
              "sender_name",
              "session_id",
              "files",
              "background_color",
              "chat_icon",
              "text_color"
            ],
            "frozen": false,
            "icon": "MessagesSquare",
            "key": "ChatInput",
            "legacy": false,
            "metadata": {},
            "minimized": true,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Chat Message",
                "group_outputs": false,
                "method": "message_response",
                "name": "message",
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "score": 0.06,
            "template": {
              "_type": "Component",
              "background_color": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Background Color",
                "dynamic": false,
                "info": "The background color of the icon.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "background_color",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "chat_icon": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Icon",
                "dynamic": false,
                "info": "The icon of the message.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "chat_icon",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.base.data.utils import IMG_FILE_TYPES, TEXT_FILE_TYPES\nfrom langflow.base.io.chat import ChatComponent\nfrom langflow.inputs.inputs import BoolInput\nfrom langflow.io import (\n    DropdownInput,\n    FileInput,\n    MessageTextInput,\n    MultilineInput,\n    Output,\n)\nfrom langflow.schema.message import Message\nfrom langflow.utils.constants import (\n    MESSAGE_SENDER_AI,\n    MESSAGE_SENDER_NAME_USER,\n    MESSAGE_SENDER_USER,\n)\n\n\nclass ChatInput(ChatComponent):\n    display_name = \"Chat Input\"\n    description = \"Get chat inputs from the Playground.\"\n    documentation: str = \"https://docs.langflow.org/components-io#chat-input\"\n    icon = \"MessagesSquare\"\n    name = \"ChatInput\"\n    minimized = True\n\n    inputs = [\n        MultilineInput(\n            name=\"input_value\",\n            display_name=\"Input Text\",\n            value=\"\",\n            info=\"Message to be passed as input.\",\n            input_types=[],\n        ),\n        BoolInput(\n            name=\"should_store_message\",\n            display_name=\"Store Messages\",\n            info=\"Store the message in the history.\",\n            value=True,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[MESSAGE_SENDER_AI, MESSAGE_SENDER_USER],\n            value=MESSAGE_SENDER_USER,\n            info=\"Type of sender.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Name of the sender.\",\n            value=MESSAGE_SENDER_NAME_USER,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            advanced=True,\n        ),\n        FileInput(\n            name=\"files\",\n            display_name=\"Files\",\n            file_types=TEXT_FILE_TYPES + IMG_FILE_TYPES,\n            info=\"Files to be sent with the message.\",\n            advanced=True,\n            is_list=True,\n            temp_file=True,\n        ),\n        MessageTextInput(\n            name=\"background_color\",\n            display_name=\"Background Color\",\n            info=\"The background color of the icon.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"chat_icon\",\n            display_name=\"Icon\",\n            info=\"The icon of the message.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"text_color\",\n            display_name=\"Text Color\",\n            info=\"The text color of the name\",\n            advanced=True,\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Chat Message\", name=\"message\", method=\"message_response\"),\n    ]\n\n    async def message_response(self) -> Message:\n        background_color = self.background_color\n        text_color = self.text_color\n        icon = self.chat_icon\n\n        message = await Message.create(\n            text=self.input_value,\n            sender=self.sender,\n            sender_name=self.sender_name,\n            session_id=self.session_id,\n            files=self.files,\n            properties={\n                \"background_color\": background_color,\n                \"text_color\": text_color,\n                \"icon\": icon,\n            },\n        )\n        if self.session_id and isinstance(message, Message) and self.should_store_message:\n            stored_message = await self.send_message(\n                message,\n            )\n            self.message.value = stored_message\n            message = stored_message\n\n        self.status = message\n        return message\n"
              },
              "files": {
                "_input_type": "FileInput",
                "advanced": true,
                "display_name": "Files",
                "dynamic": false,
                "fileTypes": [
                  "txt",
                  "md",
                  "mdx",
                  "csv",
                  "json",
                  "yaml",
                  "yml",
                  "xml",
                  "html",
                  "htm",
                  "pdf",
                  "docx",
                  "py",
                  "sh",
                  "sql",
                  "js",
                  "ts",
                  "tsx",
                  "jpg",
                  "jpeg",
                  "png",
                  "bmp",
                  "image"
                ],
                "file_path": "",
                "info": "Files to be sent with the message.",
                "list": true,
                "list_add_label": "Add More",
                "name": "files",
                "placeholder": "",
                "required": false,
                "show": true,
                "temp_file": true,
                "title_case": false,
                "trace_as_metadata": true,
                "type": "file",
                "value": ""
              },
              "input_value": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "copy_field": false,
                "display_name": "Input Text",
                "dynamic": false,
                "info": "Message to be passed as input.",
                "input_types": [],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "input_value",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "sender": {
                "_input_type": "DropdownInput",
                "advanced": true,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Sender Type",
                "dynamic": false,
                "info": "Type of sender.",
                "name": "sender",
                "options": [
                  "Machine",
                  "User"
                ],
                "options_metadata": [],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "User"
              },
              "sender_name": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Sender Name",
                "dynamic": false,
                "info": "Name of the sender.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "sender_name",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "User"
              },
              "session_id": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Session ID",
                "dynamic": false,
                "info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "session_id",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "should_store_message": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Store Messages",
                "dynamic": false,
                "info": "Store the message in the history.",
                "list": false,
                "list_add_label": "Add More",
                "name": "should_store_message",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "text_color": {
                "_input_type": "MessageTextInput",
                "advanced": true,
                "display_name": "Text Color",
                "dynamic": false,
                "info": "The text color of the name",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "text_color",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": false,
          "type": "ChatInput"
        },
        "dragging": false,
        "id": "ChatInput-OENj0",
        "measured": {
          "height": 47,
          "width": 192
        },
        "position": {
          "x": 2997.726832027867,
          "y": 1942.4036060572541
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "TextOutput-4V2cB",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "category": "input_output",
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Sends text output via API.",
            "display_name": "Text Output",
            "documentation": "https://docs.langflow.org/components-io#text-output",
            "edited": false,
            "field_order": [
              "input_value"
            ],
            "frozen": false,
            "icon": "type",
            "key": "TextOutput",
            "legacy": false,
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Output Text",
                "group_outputs": false,
                "method": "text_response",
                "name": "text",
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "score": 0.0026904540161865127,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.base.io.text import TextComponent\nfrom langflow.io import MultilineInput, Output\nfrom langflow.schema.message import Message\n\n\nclass TextOutputComponent(TextComponent):\n    display_name = \"Text Output\"\n    description = \"Sends text output via API.\"\n    documentation: str = \"https://docs.langflow.org/components-io#text-output\"\n    icon = \"type\"\n    name = \"TextOutput\"\n\n    inputs = [\n        MultilineInput(\n            name=\"input_value\",\n            display_name=\"Inputs\",\n            info=\"Text to be passed as output.\",\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Output Text\", name=\"text\", method=\"text_response\"),\n    ]\n\n    def text_response(self) -> Message:\n        message = Message(\n            text=self.input_value,\n        )\n        self.status = self.input_value\n        return message\n"
              },
              "input_value": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "copy_field": false,
                "display_name": "Inputs",
                "dynamic": false,
                "info": "Text to be passed as output.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "input_value",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "TextOutput"
        },
        "dragging": false,
        "id": "TextOutput-4V2cB",
        "measured": {
          "height": 201,
          "width": 320
        },
        "position": {
          "x": 573.9800496814019,
          "y": -822.8637785121787
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "ConditionalRouter-eF8eZ",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Routes an input message to a corresponding output based on text comparison.",
            "display_name": "If-Else",
            "documentation": "https://docs.langflow.org/components-logic#conditional-router-if-else-component",
            "edited": true,
            "field_order": [
              "input_text",
              "operator",
              "match_text",
              "case_sensitive",
              "true_case_message",
              "false_case_message",
              "max_iterations",
              "default_route"
            ],
            "frozen": false,
            "icon": "split",
            "legacy": false,
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "True",
                "group_outputs": true,
                "hidden": null,
                "method": "true_response",
                "name": "true_result",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "False",
                "group_outputs": true,
                "hidden": null,
                "method": "false_response",
                "name": "false_result",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "case_sensitive": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Case Sensitive",
                "dynamic": false,
                "info": "If true, the comparison will be case sensitive.",
                "list": false,
                "list_add_label": "Add More",
                "name": "case_sensitive",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": true
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "import re\r\n\r\nfrom langflow.custom.custom_component.component import Component\r\nfrom langflow.io import BoolInput, DropdownInput, IntInput, MessageInput, MessageTextInput, Output\r\nfrom langflow.schema.message import Message\r\n\r\n\r\nclass ConditionalRouterComponent(Component):\r\n    display_name = \"If-Else\"\r\n    description = \"Routes an input message to a corresponding output based on text comparison.\"\r\n    documentation: str = \"https://docs.langflow.org/components-logic#conditional-router-if-else-component\"\r\n    icon = \"split\"\r\n    name = \"ConditionalRouter\"\r\n\r\n    def __init__(self, *args, **kwargs):\r\n        super().__init__(*args, **kwargs)\r\n        self.__iteration_updated = False\r\n\r\n    inputs = [\r\n        MessageTextInput(\r\n            name=\"input_text\",\r\n            display_name=\"Text Input\",\r\n            info=\"The primary text input for the operation.\",\r\n            required=True,\r\n        ),\r\n        DropdownInput(\r\n            name=\"operator\",\r\n            display_name=\"Operator\",\r\n            options=[\r\n                \"equals\",\r\n                \"not equals\",\r\n                \"contains\",\r\n                \"starts with\",\r\n                \"ends with\",\r\n                \"regex\",\r\n                \"less than\",\r\n                \"less than or equal\",\r\n                \"greater than\",\r\n                \"greater than or equal\",\r\n            ],\r\n            info=\"The operator to apply for comparing the texts.\",\r\n            value=\"equals\",\r\n            real_time_refresh=True,\r\n        ),\r\n        MessageTextInput(\r\n            name=\"match_text\",\r\n            display_name=\"Match Text\",\r\n            info=\"The text input to compare against.\",\r\n            required=True,\r\n        ),\r\n        BoolInput(\r\n            name=\"case_sensitive\",\r\n            display_name=\"Case Sensitive\",\r\n            info=\"If true, the comparison will be case sensitive.\",\r\n            value=True,\r\n            advanced=True,\r\n        ),\r\n        MessageInput(\r\n            name=\"true_case_message\",\r\n            display_name=\"Case True\",\r\n            info=\"The message to pass if the condition is True.\",\r\n            advanced=True,\r\n        ),\r\n        MessageInput(\r\n            name=\"false_case_message\",\r\n            display_name=\"Case False\",\r\n            info=\"The message to pass if the condition is False.\",\r\n            advanced=True,\r\n        ),\r\n        IntInput(\r\n            name=\"max_iterations\",\r\n            display_name=\"Max Iterations\",\r\n            info=\"The maximum number of iterations for the conditional router.\",\r\n            value=10,\r\n            advanced=True,\r\n        ),\r\n        DropdownInput(\r\n            name=\"default_route\",\r\n            display_name=\"Default Route\",\r\n            options=[\"true_result\", \"false_result\"],\r\n            info=\"The default route to take when max iterations are reached.\",\r\n            value=\"false_result\",\r\n            advanced=True,\r\n        ),\r\n    ]\r\n\r\n    outputs = [\r\n        Output(display_name=\"True\", name=\"true_result\", method=\"true_response\", group_outputs=True),\r\n        Output(display_name=\"False\", name=\"false_result\", method=\"false_response\", group_outputs=True),\r\n    ]\r\n\r\n    def _pre_run_setup(self):\r\n        self.__iteration_updated = False\r\n\r\n    def evaluate_condition(self, input_text: str, match_text: str, operator: str, *, case_sensitive: bool) -> bool:\r\n        if not case_sensitive and operator != \"regex\":\r\n            input_text = input_text.lower()\r\n            match_text = match_text.lower()\r\n\r\n        if operator == \"equals\":\r\n            return input_text == match_text\r\n        if operator == \"not equals\":\r\n            return input_text != match_text\r\n        if operator == \"contains\":\r\n            return match_text in input_text\r\n        if operator == \"starts with\":\r\n            return input_text.startswith(match_text)\r\n        if operator == \"ends with\":\r\n            return input_text.endswith(match_text)\r\n        if operator == \"regex\":\r\n            try:\r\n                return bool(re.match(match_text, input_text))\r\n            except re.error:\r\n                return False  # Return False if the regex is invalid\r\n        if operator in [\"less than\", \"less than or equal\", \"greater than\", \"greater than or equal\"]:\r\n            try:\r\n                input_num = float(input_text)\r\n                match_num = float(match_text)\r\n                if operator == \"less than\":\r\n                    return input_num < match_num\r\n                if operator == \"less than or equal\":\r\n                    return input_num <= match_num\r\n                if operator == \"greater than\":\r\n                    return input_num > match_num\r\n                if operator == \"greater than or equal\":\r\n                    return input_num >= match_num\r\n            except ValueError:\r\n                return False  # Invalid number format for comparison\r\n        return False\r\n\r\n    def iterate_and_stop_once(self, route_to_stop: str):\r\n        if not self.__iteration_updated:\r\n            self.update_ctx({f\"{self._id}_iteration\": self.ctx.get(f\"{self._id}_iteration\", 0) + 1})\r\n            self.__iteration_updated = True\r\n            if self.ctx.get(f\"{self._id}_iteration\", 0) >= self.max_iterations and route_to_stop == self.default_route:\r\n                route_to_stop = \"true_result\" if route_to_stop == \"false_result\" else \"false_result\"\r\n            self.stop(route_to_stop)\r\n\r\n    def true_response(self) -> Message:\r\n        result = self.evaluate_condition(\r\n            self.input_text, self.match_text, self.operator, case_sensitive=self.case_sensitive\r\n        )\r\n        if result:\r\n            self.status = self.true_case_message\r\n            self.iterate_and_stop_once(\"false_result\")\r\n            return self.true_case_message\r\n        self.iterate_and_stop_once(\"true_result\")\r\n        return Message(content=\"\")\r\n\r\n    def false_response(self) -> Message:\r\n        result = self.evaluate_condition(\r\n            self.input_text, self.match_text, self.operator, case_sensitive=self.case_sensitive\r\n        )\r\n        if not result:\r\n            self.status = self.false_case_message\r\n            self.iterate_and_stop_once(\"true_result\")\r\n            return self.false_case_message\r\n        self.iterate_and_stop_once(\"false_result\")\r\n        return Message(content=\"\")\r\n\r\n    def update_build_config(self, build_config: dict, field_value: str, field_name: str | None = None) -> dict:\r\n        if field_name == \"operator\":\r\n            if field_value == \"regex\":\r\n                build_config.pop(\"case_sensitive\", None)\r\n            elif \"case_sensitive\" not in build_config:\r\n                case_sensitive_input = next(\r\n                    (input_field for input_field in self.inputs if input_field.name == \"case_sensitive\"), None\r\n                )\r\n                if case_sensitive_input:\r\n                    build_config[\"case_sensitive\"] = case_sensitive_input.to_dict()\r\n        return build_config\r\n"
              },
              "default_route": {
                "_input_type": "DropdownInput",
                "advanced": true,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Default Route",
                "dynamic": false,
                "info": "The default route to take when max iterations are reached.",
                "name": "default_route",
                "options": [
                  "true_result",
                  "false_result"
                ],
                "options_metadata": [],
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "false_result"
              },
              "false_case_message": {
                "_input_type": "MessageInput",
                "advanced": true,
                "display_name": "Case False",
                "dynamic": false,
                "info": "The message to pass if the condition is False.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "false_case_message",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "input_text": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Text Input",
                "dynamic": false,
                "info": "The primary text input for the operation.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "input_text",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "match_text": {
                "_input_type": "MessageTextInput",
                "advanced": false,
                "display_name": "Match Text",
                "dynamic": false,
                "info": "The text input to compare against.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "match_text",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "end"
              },
              "max_iterations": {
                "_input_type": "IntInput",
                "advanced": true,
                "display_name": "Max Iterations",
                "dynamic": false,
                "info": "The maximum number of iterations for the conditional router.",
                "list": false,
                "list_add_label": "Add More",
                "name": "max_iterations",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "int",
                "value": 10
              },
              "operator": {
                "_input_type": "DropdownInput",
                "advanced": false,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Operator",
                "dynamic": false,
                "info": "The operator to apply for comparing the texts.",
                "name": "operator",
                "options": [
                  "equals",
                  "not equals",
                  "contains",
                  "starts with",
                  "ends with",
                  "regex",
                  "less than",
                  "less than or equal",
                  "greater than",
                  "greater than or equal"
                ],
                "options_metadata": [],
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "equals"
              },
              "true_case_message": {
                "_input_type": "MessageInput",
                "advanced": true,
                "display_name": "Case True",
                "dynamic": false,
                "info": "The message to pass if the condition is True.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "true_case_message",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "ConditionalRouter"
        },
        "dragging": false,
        "id": "ConditionalRouter-eF8eZ",
        "measured": {
          "height": 426,
          "width": 320
        },
        "position": {
          "x": 6665.095645797623,
          "y": -608.6791561364363
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "PythonREPLComponent-oGIp4",
          "node": {
            "base_classes": [
              "Data"
            ],
            "beta": false,
            "category": "processing",
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Run Python code with optional imports. Use print() to see the output.",
            "display_name": "CheckFeedbackLoop",
            "documentation": "https://docs.langflow.org/components-processing#python-interpreter",
            "edited": false,
            "field_order": [
              "global_imports",
              "python_code"
            ],
            "frozen": false,
            "icon": "square-terminal",
            "key": "PythonREPLComponent",
            "legacy": false,
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Results",
                "group_outputs": false,
                "method": "run_python_repl",
                "name": "results",
                "selected": "Data",
                "tool_mode": true,
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "score": 0.0029853505685675905,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "import importlib\n\nfrom langchain_experimental.utilities import PythonREPL\n\nfrom langflow.custom.custom_component.component import Component\nfrom langflow.io import CodeInput, Output, StrInput\nfrom langflow.schema.data import Data\n\n\nclass PythonREPLComponent(Component):\n    display_name = \"Python Interpreter\"\n    description = \"Run Python code with optional imports. Use print() to see the output.\"\n    documentation: str = \"https://docs.langflow.org/components-processing#python-interpreter\"\n    icon = \"square-terminal\"\n\n    inputs = [\n        StrInput(\n            name=\"global_imports\",\n            display_name=\"Global Imports\",\n            info=\"A comma-separated list of modules to import globally, e.g. 'math,numpy,pandas'.\",\n            value=\"math,pandas\",\n            required=True,\n        ),\n        CodeInput(\n            name=\"python_code\",\n            display_name=\"Python Code\",\n            info=\"The Python code to execute. Only modules specified in Global Imports can be used.\",\n            value=\"print('Hello, World!')\",\n            input_types=[\"Message\"],\n            tool_mode=True,\n            required=True,\n        ),\n    ]\n\n    outputs = [\n        Output(\n            display_name=\"Results\",\n            name=\"results\",\n            type_=Data,\n            method=\"run_python_repl\",\n        ),\n    ]\n\n    def get_globals(self, global_imports: str | list[str]) -> dict:\n        \"\"\"Create a globals dictionary with only the specified allowed imports.\"\"\"\n        global_dict = {}\n\n        try:\n            if isinstance(global_imports, str):\n                modules = [module.strip() for module in global_imports.split(\",\")]\n            elif isinstance(global_imports, list):\n                modules = global_imports\n            else:\n                msg = \"global_imports must be either a string or a list\"\n                raise TypeError(msg)\n\n            for module in modules:\n                try:\n                    imported_module = importlib.import_module(module)\n                    global_dict[imported_module.__name__] = imported_module\n                except ImportError as e:\n                    msg = f\"Could not import module {module}: {e!s}\"\n                    raise ImportError(msg) from e\n\n        except Exception as e:\n            self.log(f\"Error in global imports: {e!s}\")\n            raise\n        else:\n            self.log(f\"Successfully imported modules: {list(global_dict.keys())}\")\n            return global_dict\n\n    def run_python_repl(self) -> Data:\n        try:\n            globals_ = self.get_globals(self.global_imports)\n            python_repl = PythonREPL(_globals=globals_)\n            result = python_repl.run(self.python_code)\n            result = result.strip() if result else \"\"\n\n            self.log(\"Code execution completed successfully\")\n            return Data(data={\"result\": result})\n\n        except ImportError as e:\n            error_message = f\"Import Error: {e!s}\"\n            self.log(error_message)\n            return Data(data={\"error\": error_message})\n\n        except SyntaxError as e:\n            error_message = f\"Syntax Error: {e!s}\"\n            self.log(error_message)\n            return Data(data={\"error\": error_message})\n\n        except (NameError, TypeError, ValueError) as e:\n            error_message = f\"Error during execution: {e!s}\"\n            self.log(error_message)\n            return Data(data={\"error\": error_message})\n\n    def build(self):\n        return self.run_python_repl\n"
              },
              "global_imports": {
                "_input_type": "StrInput",
                "advanced": false,
                "display_name": "Global Imports",
                "dynamic": false,
                "info": "A comma-separated list of modules to import globally, e.g. 'math,numpy,pandas'.",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "global_imports",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "math,pandas"
              },
              "python_code": {
                "_input_type": "CodeInput",
                "advanced": false,
                "display_name": "Python Code",
                "dynamic": false,
                "info": "The Python code to execute. Only modules specified in Global Imports can be used.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "python_code",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": true,
                "trace_as_input": true,
                "type": "code",
                "value": "import json\r\nfrom datetime import datetime\r\n\r\n# Get values from flow_vars\r\ndifficulty = flow_vars.get(\"difficulty\", \"unknown\")\r\nsubject = flow_vars.get(\"subject\", \"unknown\")\r\ntopic = flow_vars.get(\"topic\", \"unknown\")\r\nnum_questions = flow_vars.get(\"num_questions\", \"unknown\")\r\ngenerated_output = flow_vars.get(\"original_output\", \"\")\r\nimproved_output = flow_vars.get(\"improved_output\", \"\")\r\nfeedback = flow_vars.get(\"feedback\", inputs[0]).lower()\r\n\r\n# Save feedback log\r\ndata = {\r\n    \"timestamp\": str(datetime.now()),\r\n    \"difficulty\": difficulty,\r\n    \"subject\": subject,\r\n    \"topic\": topic,\r\n    \"num_questions\": num_questions,\r\n    \"generated_output\": generated_output,\r\n    \"feedback\": feedback,\r\n    \"improved_output\": improved_output,\r\n    \"loop\": flow_vars.get(\"loop_count\", 1)\r\n}\r\n\r\nwith open(\"/mnt/data/qa_feedback_log.json\", \"a\") as f:\r\n    f.write(json.dumps(data) + \"\\n\")\r\n\r\n# Update loop count\r\nflow_vars[\"loop_count\"] = flow_vars.get(\"loop_count\", 0) + 1\r\n\r\n# Decide whether to stop or regenerate\r\nif \"good\" in feedback or \"okay\" in feedback or \"satisfied\" in feedback:\r\n    return \"end\"\r\nelif flow_vars[\"loop_count\"] >= 3:\r\n    return \"end\"\r\nelse:\r\n    return \"regenerate\"\r\n"
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "PythonREPLComponent"
        },
        "dragging": false,
        "id": "PythonREPLComponent-oGIp4",
        "measured": {
          "height": 306,
          "width": 320
        },
        "position": {
          "x": 5557.145594452875,
          "y": -416.644833635348
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "LanguageModelComponent-UNDHX",
          "node": {
            "base_classes": [
              "LanguageModel",
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Runs a language model given a specified provider.",
            "display_name": "Language Model",
            "documentation": "https://docs.langflow.org/components-models",
            "edited": true,
            "field_order": [
              "provider",
              "model_name",
              "api_key",
              "base_url",
              "input_value",
              "system_message",
              "stream",
              "temperature"
            ],
            "frozen": false,
            "icon": "brain-circuit",
            "last_updated": "2025-07-22T19:08:25.224Z",
            "legacy": false,
            "metadata": {
              "keywords": [
                "model",
                "llm",
                "language model",
                "large language model"
              ]
            },
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Model Response",
                "group_outputs": false,
                "hidden": null,
                "method": "text_response",
                "name": "text_output",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              },
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Language Model",
                "group_outputs": false,
                "hidden": null,
                "method": "build_model",
                "name": "model_output",
                "options": null,
                "required_inputs": null,
                "selected": "LanguageModel",
                "tool_mode": true,
                "types": [
                  "LanguageModel"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "priority": 0,
            "template": {
              "_type": "Component",
              "api_key": {
                "_input_type": "SecretStrInput",
                "advanced": false,
                "display_name": "No API Key Needed",
                "dynamic": false,
                "info": "Model Provider API key",
                "input_types": [],
                "load_from_db": false,
                "name": "api_key",
                "password": true,
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": false,
                "title_case": false,
                "type": "str",
                "value": ""
              },
              "base_url": {
                "_input_type": "MultilineInput",
                "advanced": true,
                "copy_field": false,
                "display_name": "Ollama Base URL",
                "dynamic": false,
                "info": "Optional: Override Ollama base URL",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "base_url",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": "http://localhost:11434"
              },
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from typing import Any\r\n\r\nfrom langchain_anthropic import ChatAnthropic\r\nfrom langchain_google_genai import ChatGoogleGenerativeAI\r\nfrom langchain_openai import ChatOpenAI\r\nfrom langchain_community.chat_models import ChatOllama  # ✅ Ollama import\r\n\r\nfrom langflow.base.models.anthropic_constants import ANTHROPIC_MODELS\r\nfrom langflow.base.models.google_generative_ai_constants import GOOGLE_GENERATIVE_AI_MODELS\r\nfrom langflow.base.models.model import LCModelComponent\r\nfrom langflow.base.models.openai_constants import OPENAI_CHAT_MODEL_NAMES, OPENAI_REASONING_MODEL_NAMES\r\nfrom langflow.field_typing import LanguageModel\r\nfrom langflow.field_typing.range_spec import RangeSpec\r\nfrom langflow.inputs.inputs import BoolInput\r\nfrom langflow.io import DropdownInput, MessageInput, MultilineInput, SecretStrInput, SliderInput\r\nfrom langflow.schema.dotdict import dotdict\r\n\r\n\r\nclass LanguageModelComponent(LCModelComponent):\r\n    display_name = \"Language Model\"\r\n    description = \"Runs a language model given a specified provider.\"\r\n    documentation: str = \"https://docs.langflow.org/components-models\"\r\n    icon = \"brain-circuit\"\r\n    category = \"models\"\r\n    priority = 0  # Set priority to 0 to make it appear first\r\n\r\n    inputs = [\r\n        DropdownInput(\r\n            name=\"provider\",\r\n            display_name=\"Model Provider\",\r\n            options=[\"OpenAI\", \"Anthropic\", \"Google\", \"Ollama\"],\r\n            value=\"OpenAI\",\r\n            info=\"Select the model provider\",\r\n            real_time_refresh=True,\r\n            options_metadata=[\r\n                {\"icon\": \"OpenAI\"},\r\n                {\"icon\": \"Anthropic\"},\r\n                {\"icon\": \"GoogleGenerativeAI\"},\r\n                {\"icon\": \"Bot\"},\r\n            ],\r\n        ),\r\n        DropdownInput(\r\n            name=\"model_name\",\r\n            display_name=\"Model Name\",\r\n            options=OPENAI_CHAT_MODEL_NAMES + OPENAI_REASONING_MODEL_NAMES,\r\n            value=OPENAI_CHAT_MODEL_NAMES[0],\r\n            info=\"Select the model to use\",\r\n            real_time_refresh=True,\r\n        ),\r\n        SecretStrInput(\r\n            name=\"api_key\",\r\n            display_name=\"OpenAI API Key\",\r\n            info=\"Model Provider API key\",\r\n            required=False,\r\n            show=True,\r\n            real_time_refresh=True,\r\n        ),\r\n        MultilineInput(\r\n            name=\"base_url\",\r\n            display_name=\"Ollama Base URL\",\r\n            value=\"http://localhost:11434\",\r\n            info=\"Optional: Override Ollama base URL\",\r\n            advanced=True,\r\n        ),\r\n        MessageInput(\r\n            name=\"input_value\",\r\n            display_name=\"Input\",\r\n            info=\"The input text to send to the model\",\r\n        ),\r\n        MultilineInput(\r\n            name=\"system_message\",\r\n            display_name=\"System Message\",\r\n            info=\"A system message that helps set the behavior of the assistant\",\r\n            advanced=False,\r\n        ),\r\n        BoolInput(\r\n            name=\"stream\",\r\n            display_name=\"Stream\",\r\n            info=\"Whether to stream the response\",\r\n            value=False,\r\n            advanced=True,\r\n        ),\r\n        SliderInput(\r\n            name=\"temperature\",\r\n            display_name=\"Temperature\",\r\n            value=0.1,\r\n            info=\"Controls randomness in responses\",\r\n            range_spec=RangeSpec(min=0, max=1, step=0.01),\r\n            advanced=True,\r\n        ),\r\n    ]\r\n\r\n    def build_model(self) -> LanguageModel:\r\n        provider = self.provider\r\n        model_name = self.model_name\r\n        temperature = self.temperature\r\n        stream = self.stream\r\n\r\n        if provider == \"OpenAI\":\r\n            if not self.api_key:\r\n                msg = \"OpenAI API key is required when using OpenAI provider\"\r\n                raise ValueError(msg)\r\n\r\n            if model_name in OPENAI_REASONING_MODEL_NAMES:\r\n                temperature = None  # Reasoning models don't support temperature\r\n\r\n            return ChatOpenAI(\r\n                model_name=model_name,\r\n                temperature=temperature,\r\n                streaming=stream,\r\n                openai_api_key=self.api_key,\r\n            )\r\n\r\n        if provider == \"Anthropic\":\r\n            if not self.api_key:\r\n                msg = \"Anthropic API key is required when using Anthropic provider\"\r\n                raise ValueError(msg)\r\n            return ChatAnthropic(\r\n                model=model_name,\r\n                temperature=temperature,\r\n                streaming=stream,\r\n                anthropic_api_key=self.api_key,\r\n            )\r\n\r\n        if provider == \"Google\":\r\n            if not self.api_key:\r\n                msg = \"Google API key is required when using Google provider\"\r\n                raise ValueError(msg)\r\n            return ChatGoogleGenerativeAI(\r\n                model=model_name,\r\n                temperature=temperature,\r\n                streaming=stream,\r\n                google_api_key=self.api_key,\r\n            )\r\n\r\n        if provider == \"Ollama\":\r\n            return ChatOllama(\r\n                model=model_name,\r\n                temperature=temperature,\r\n                streaming=stream,\r\n                base_url=self.base_url or \"http://localhost:11434\",\r\n            )\r\n\r\n        raise ValueError(f\"Unknown provider: {provider}\")\r\n\r\n    def update_build_config(self, build_config: dotdict, field_value: Any, field_name: str | None = None) -> dotdict:\r\n        if field_name == \"provider\":\r\n            if field_value == \"OpenAI\":\r\n                build_config[\"model_name\"][\"options\"] = OPENAI_CHAT_MODEL_NAMES + OPENAI_REASONING_MODEL_NAMES\r\n                build_config[\"model_name\"][\"value\"] = OPENAI_CHAT_MODEL_NAMES[0]\r\n                build_config[\"api_key\"][\"display_name\"] = \"OpenAI API Key\"\r\n                build_config[\"api_key\"][\"show\"] = True\r\n            elif field_value == \"Anthropic\":\r\n                build_config[\"model_name\"][\"options\"] = ANTHROPIC_MODELS\r\n                build_config[\"model_name\"][\"value\"] = ANTHROPIC_MODELS[0]\r\n                build_config[\"api_key\"][\"display_name\"] = \"Anthropic API Key\"\r\n                build_config[\"api_key\"][\"show\"] = True\r\n            elif field_value == \"Google\":\r\n                build_config[\"model_name\"][\"options\"] = GOOGLE_GENERATIVE_AI_MODELS\r\n                build_config[\"model_name\"][\"value\"] = GOOGLE_GENERATIVE_AI_MODELS[0]\r\n                build_config[\"api_key\"][\"display_name\"] = \"Google API Key\"\r\n                build_config[\"api_key\"][\"show\"] = True\r\n            elif field_value == \"Ollama\":\r\n                build_config[\"model_name\"][\"options\"] = [\"llama3\", \"mistral\", \"codellama\", \"llama2\"]\r\n                build_config[\"model_name\"][\"value\"] = \"llama3\"\r\n                build_config[\"api_key\"][\"display_name\"] = \"No API Key Needed\"\r\n                build_config[\"api_key\"][\"show\"] = False\r\n        elif field_name == \"model_name\" and field_value.startswith(\"o1\") and self.provider == \"OpenAI\":\r\n            if \"system_message\" in build_config:\r\n                build_config[\"system_message\"][\"show\"] = False\r\n        elif field_name == \"model_name\" and not field_value.startswith(\"o1\") and \"system_message\" in build_config:\r\n            build_config[\"system_message\"][\"show\"] = True\r\n        return build_config\r\n\r\n"
              },
              "input_value": {
                "_input_type": "MessageInput",
                "advanced": false,
                "display_name": "Input",
                "dynamic": false,
                "info": "The input text to send to the model",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "input_value",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "model_name": {
                "_input_type": "DropdownInput",
                "advanced": false,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Model Name",
                "dynamic": false,
                "info": "Select the model to use",
                "name": "model_name",
                "options": [
                  "llama3",
                  "mistral",
                  "codellama",
                  "llama2"
                ],
                "options_metadata": [],
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "llama3"
              },
              "provider": {
                "_input_type": "DropdownInput",
                "advanced": false,
                "combobox": false,
                "dialog_inputs": {},
                "display_name": "Model Provider",
                "dynamic": false,
                "info": "Select the model provider",
                "name": "provider",
                "options": [
                  "OpenAI",
                  "Anthropic",
                  "Google",
                  "Ollama"
                ],
                "options_metadata": [
                  {
                    "icon": "OpenAI"
                  },
                  {
                    "icon": "Anthropic"
                  },
                  {
                    "icon": "GoogleGenerativeAI"
                  },
                  {
                    "icon": "Bot"
                  }
                ],
                "placeholder": "",
                "real_time_refresh": true,
                "required": false,
                "show": true,
                "title_case": false,
                "toggle": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "Ollama"
              },
              "stream": {
                "_input_type": "BoolInput",
                "advanced": true,
                "display_name": "Stream",
                "dynamic": false,
                "info": "Whether to stream the response",
                "list": false,
                "list_add_label": "Add More",
                "name": "stream",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "bool",
                "value": false
              },
              "system_message": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "copy_field": false,
                "display_name": "System Message",
                "dynamic": false,
                "info": "A system message that helps set the behavior of the assistant",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "system_message",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              },
              "temperature": {
                "_input_type": "SliderInput",
                "advanced": true,
                "display_name": "Temperature",
                "dynamic": false,
                "info": "Controls randomness in responses",
                "max_label": "",
                "max_label_icon": "",
                "min_label": "",
                "min_label_icon": "",
                "name": "temperature",
                "placeholder": "",
                "range_spec": {
                  "max": 1,
                  "min": 0,
                  "step": 0.01,
                  "step_type": "float"
                },
                "required": false,
                "show": true,
                "slider_buttons": false,
                "slider_buttons_options": [],
                "slider_input": false,
                "title_case": false,
                "tool_mode": false,
                "type": "slider",
                "value": 0.1
              }
            },
            "tool_mode": false
          },
          "selected_output": "text_output",
          "showNode": true,
          "type": "LanguageModelComponent"
        },
        "dragging": false,
        "id": "LanguageModelComponent-UNDHX",
        "measured": {
          "height": 447,
          "width": 320
        },
        "position": {
          "x": 7322.535155252641,
          "y": 2069.441301727281
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "TextOutput-ujpFk",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Sends text output via API.",
            "display_name": "Text Output",
            "documentation": "https://docs.langflow.org/components-io#text-output",
            "edited": false,
            "field_order": [
              "input_value"
            ],
            "frozen": false,
            "icon": "type",
            "legacy": false,
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Output Text",
                "group_outputs": false,
                "method": "text_response",
                "name": "text",
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.base.io.text import TextComponent\nfrom langflow.io import MultilineInput, Output\nfrom langflow.schema.message import Message\n\n\nclass TextOutputComponent(TextComponent):\n    display_name = \"Text Output\"\n    description = \"Sends text output via API.\"\n    documentation: str = \"https://docs.langflow.org/components-io#text-output\"\n    icon = \"type\"\n    name = \"TextOutput\"\n\n    inputs = [\n        MultilineInput(\n            name=\"input_value\",\n            display_name=\"Inputs\",\n            info=\"Text to be passed as output.\",\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Output Text\", name=\"text\", method=\"text_response\"),\n    ]\n\n    def text_response(self) -> Message:\n        message = Message(\n            text=self.input_value,\n        )\n        self.status = self.input_value\n        return message\n"
              },
              "input_value": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "copy_field": false,
                "display_name": "Inputs",
                "dynamic": false,
                "info": "Text to be passed as output.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "input_value",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "TextOutput"
        },
        "dragging": false,
        "id": "TextOutput-ujpFk",
        "measured": {
          "height": 201,
          "width": 320
        },
        "position": {
          "x": 7114.1555976598875,
          "y": -623.2878523747828
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "PythonREPLComponent-2yl0o",
          "node": {
            "base_classes": [
              "Data"
            ],
            "beta": false,
            "category": "processing",
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Run Python code with optional imports. Use print() to see the output.",
            "display_name": "Python Interpreter",
            "documentation": "https://docs.langflow.org/components-processing#python-interpreter",
            "edited": false,
            "field_order": [
              "global_imports",
              "python_code"
            ],
            "frozen": false,
            "icon": "square-terminal",
            "key": "PythonREPLComponent",
            "legacy": false,
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Results",
                "group_outputs": false,
                "method": "run_python_repl",
                "name": "results",
                "selected": "Data",
                "tool_mode": true,
                "types": [
                  "Data"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "score": 0.0029853505685675905,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "import importlib\n\nfrom langchain_experimental.utilities import PythonREPL\n\nfrom langflow.custom.custom_component.component import Component\nfrom langflow.io import CodeInput, Output, StrInput\nfrom langflow.schema.data import Data\n\n\nclass PythonREPLComponent(Component):\n    display_name = \"Python Interpreter\"\n    description = \"Run Python code with optional imports. Use print() to see the output.\"\n    documentation: str = \"https://docs.langflow.org/components-processing#python-interpreter\"\n    icon = \"square-terminal\"\n\n    inputs = [\n        StrInput(\n            name=\"global_imports\",\n            display_name=\"Global Imports\",\n            info=\"A comma-separated list of modules to import globally, e.g. 'math,numpy,pandas'.\",\n            value=\"math,pandas\",\n            required=True,\n        ),\n        CodeInput(\n            name=\"python_code\",\n            display_name=\"Python Code\",\n            info=\"The Python code to execute. Only modules specified in Global Imports can be used.\",\n            value=\"print('Hello, World!')\",\n            input_types=[\"Message\"],\n            tool_mode=True,\n            required=True,\n        ),\n    ]\n\n    outputs = [\n        Output(\n            display_name=\"Results\",\n            name=\"results\",\n            type_=Data,\n            method=\"run_python_repl\",\n        ),\n    ]\n\n    def get_globals(self, global_imports: str | list[str]) -> dict:\n        \"\"\"Create a globals dictionary with only the specified allowed imports.\"\"\"\n        global_dict = {}\n\n        try:\n            if isinstance(global_imports, str):\n                modules = [module.strip() for module in global_imports.split(\",\")]\n            elif isinstance(global_imports, list):\n                modules = global_imports\n            else:\n                msg = \"global_imports must be either a string or a list\"\n                raise TypeError(msg)\n\n            for module in modules:\n                try:\n                    imported_module = importlib.import_module(module)\n                    global_dict[imported_module.__name__] = imported_module\n                except ImportError as e:\n                    msg = f\"Could not import module {module}: {e!s}\"\n                    raise ImportError(msg) from e\n\n        except Exception as e:\n            self.log(f\"Error in global imports: {e!s}\")\n            raise\n        else:\n            self.log(f\"Successfully imported modules: {list(global_dict.keys())}\")\n            return global_dict\n\n    def run_python_repl(self) -> Data:\n        try:\n            globals_ = self.get_globals(self.global_imports)\n            python_repl = PythonREPL(_globals=globals_)\n            result = python_repl.run(self.python_code)\n            result = result.strip() if result else \"\"\n\n            self.log(\"Code execution completed successfully\")\n            return Data(data={\"result\": result})\n\n        except ImportError as e:\n            error_message = f\"Import Error: {e!s}\"\n            self.log(error_message)\n            return Data(data={\"error\": error_message})\n\n        except SyntaxError as e:\n            error_message = f\"Syntax Error: {e!s}\"\n            self.log(error_message)\n            return Data(data={\"error\": error_message})\n\n        except (NameError, TypeError, ValueError) as e:\n            error_message = f\"Error during execution: {e!s}\"\n            self.log(error_message)\n            return Data(data={\"error\": error_message})\n\n    def build(self):\n        return self.run_python_repl\n"
              },
              "global_imports": {
                "_input_type": "StrInput",
                "advanced": false,
                "display_name": "Global Imports",
                "dynamic": false,
                "info": "A comma-separated list of modules to import globally, e.g. 'math,numpy,pandas'.",
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "name": "global_imports",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_metadata": true,
                "type": "str",
                "value": "math,pandas"
              },
              "python_code": {
                "_input_type": "CodeInput",
                "advanced": false,
                "display_name": "Python Code",
                "dynamic": false,
                "info": "The Python code to execute. Only modules specified in Global Imports can be used.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "python_code",
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "tool_mode": true,
                "trace_as_input": true,
                "type": "code",
                "value": "import re\n\noutput = inputs[0]\n\n# Use regex to extract the Improved and Feedback sections\nimproved_match = re.search(r\"Improved:\\s*(.*)\", output, re.DOTALL)\nfeedback_match = re.search(r\"Feedback:\\s*(.*)\", output)\n\nflow_vars[\"improved_output\"] = improved_match.group(1).strip() if improved_match else \"\"\nflow_vars[\"feedback\"] = feedback_match.group(1).strip().lower() if feedback_match else \"\"\n\n# Return the feedback string so it can be passed into CheckFeedbackLoop\nreturn flow_vars[\"feedback\"]"
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "PythonREPLComponent"
        },
        "dragging": false,
        "id": "PythonREPLComponent-2yl0o",
        "measured": {
          "height": 306,
          "width": 320
        },
        "position": {
          "x": 4953.105580741202,
          "y": -423.63698227676593
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "CustomComponent-jNho1",
          "node": {
            "base_classes": [
              "Text"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Extracts a text string from API response data.",
            "display_name": "Data to Text",
            "documentation": "https://docs.langflow.org/components-custom-components",
            "edited": true,
            "field_order": [
              "data"
            ],
            "frozen": false,
            "icon": "message",
            "legacy": false,
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Text",
                "group_outputs": false,
                "hidden": null,
                "method": "extract_text",
                "name": "text",
                "options": null,
                "required_inputs": null,
                "selected": "Text",
                "tool_mode": true,
                "types": [
                  "Text"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.custom.custom_component.component import Component\r\nfrom langflow.io import DataInput, Output\r\n\r\nclass DataToTextComponent(Component):\r\n    display_name = \"Data to Text\"\r\n    description = \"Extracts a text string from API response data.\"\r\n    documentation: str = \"https://docs.langflow.org/components-custom-components\"\r\n    icon = \"message\"\r\n    name = \"DataToTextComponent\"\r\n\r\n    inputs = [\r\n        DataInput(\r\n            name=\"data\",\r\n            display_name=\"Data\",\r\n            info=\"API response data (dict, JSON, or text).\",\r\n            value={},\r\n            tool_mode=True,\r\n        ),\r\n    ]\r\n\r\n    outputs = [\r\n        Output(display_name=\"Text\", name=\"text\", method=\"extract_text\"),  # <- method name\r\n    ]\r\n\r\n    def extract_text(self) -> str:\r\n        data = self.data\r\n        if isinstance(data, dict):\r\n            if \"data\" in data and \"message\" in data[\"data\"]:\r\n                msg = data[\"data\"][\"message\"]\r\n            elif \"message\" in data:\r\n                msg = data[\"message\"]\r\n            else:\r\n                msg = str(data)\r\n        else:\r\n            msg = str(data)\r\n        return msg  # <- plain string\r\n"
              },
              "data": {
                "_input_type": "DataInput",
                "advanced": false,
                "display_name": "Data",
                "dynamic": false,
                "info": "API response data (dict, JSON, or text).",
                "input_types": [
                  "Data"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "data",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "other",
                "value": {}
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "DataToTextComponent"
        },
        "dragging": false,
        "id": "CustomComponent-jNho1",
        "measured": {
          "height": 164,
          "width": 320
        },
        "position": {
          "x": 5958.944763592999,
          "y": -661.5489042976684
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "CustomComponent-tj89C",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Extracts a message string from API response data and outputs as a Message object.",
            "display_name": "Data to Message",
            "documentation": "https://docs.langflow.org/components-custom-components",
            "edited": true,
            "field_order": [
              "data"
            ],
            "frozen": false,
            "icon": "message",
            "legacy": false,
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Message",
                "group_outputs": false,
                "hidden": null,
                "method": "build_message",
                "name": "message",
                "options": null,
                "required_inputs": null,
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.custom.custom_component.component import Component\r\nfrom langflow.io import DataInput, Output\r\nfrom langflow.schema.message import Message  # Import the Message class\r\n\r\nclass DataToMessageComponent(Component):\r\n    display_name = \"Data to Message\"\r\n    description = \"Extracts a message string from API response data and outputs as a Message object.\"\r\n    documentation: str = \"https://docs.langflow.org/components-custom-components\"\r\n    icon = \"message\"\r\n    name = \"DataToMessageComponent\"\r\n\r\n    inputs = [\r\n        DataInput(\r\n            name=\"data\",\r\n            display_name=\"Data\",\r\n            info=\"API response data (dict, JSON, or text).\",\r\n            value={},\r\n            tool_mode=True,\r\n        ),\r\n    ]\r\n\r\n    outputs = [\r\n        Output(display_name=\"Message\", name=\"message\", method=\"build_message\"),\r\n    ]\r\n\r\n    def build_message(self) -> Message:\r\n        data = self.data\r\n        # Try to extract the message from common API response structures\r\n        if isinstance(data, dict):\r\n            if \"data\" in data and \"message\" in data[\"data\"]:\r\n                msg = data[\"data\"][\"message\"]\r\n            elif \"message\" in data:\r\n                msg = data[\"message\"]\r\n            else:\r\n                msg = str(data)\r\n        else:\r\n            msg = str(data)\r\n        return Message(content=msg)  # Output as a Message object\r\n"
              },
              "data": {
                "_input_type": "DataInput",
                "advanced": false,
                "display_name": "Data",
                "dynamic": false,
                "info": "API response data (dict, JSON, or text).",
                "input_types": [
                  "Data"
                ],
                "list": false,
                "list_add_label": "Add More",
                "name": "data",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": true,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "other",
                "value": {}
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "DataToMessageComponent"
        },
        "dragging": false,
        "id": "CustomComponent-tj89C",
        "measured": {
          "height": 180,
          "width": 320
        },
        "position": {
          "x": 5953.339501864105,
          "y": -921.909802573178
        },
        "selected": false,
        "type": "genericNode"
      },
      {
        "data": {
          "id": "TextOutput-REnHF",
          "node": {
            "base_classes": [
              "Message"
            ],
            "beta": false,
            "conditional_paths": [],
            "custom_fields": {},
            "description": "Sends text output via API.",
            "display_name": "MCQ/",
            "documentation": "https://docs.langflow.org/components-io#text-output",
            "edited": false,
            "field_order": [
              "input_value"
            ],
            "frozen": false,
            "icon": "type",
            "legacy": false,
            "metadata": {},
            "minimized": false,
            "output_types": [],
            "outputs": [
              {
                "allows_loop": false,
                "cache": true,
                "display_name": "Output Text",
                "group_outputs": false,
                "method": "text_response",
                "name": "text",
                "selected": "Message",
                "tool_mode": true,
                "types": [
                  "Message"
                ],
                "value": "__UNDEFINED__"
              }
            ],
            "pinned": false,
            "template": {
              "_type": "Component",
              "code": {
                "advanced": true,
                "dynamic": true,
                "fileTypes": [],
                "file_path": "",
                "info": "",
                "list": false,
                "load_from_db": false,
                "multiline": true,
                "name": "code",
                "password": false,
                "placeholder": "",
                "required": true,
                "show": true,
                "title_case": false,
                "type": "code",
                "value": "from langflow.base.io.text import TextComponent\nfrom langflow.io import MultilineInput, Output\nfrom langflow.schema.message import Message\n\n\nclass TextOutputComponent(TextComponent):\n    display_name = \"Text Output\"\n    description = \"Sends text output via API.\"\n    documentation: str = \"https://docs.langflow.org/components-io#text-output\"\n    icon = \"type\"\n    name = \"TextOutput\"\n\n    inputs = [\n        MultilineInput(\n            name=\"input_value\",\n            display_name=\"Inputs\",\n            info=\"Text to be passed as output.\",\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Output Text\", name=\"text\", method=\"text_response\"),\n    ]\n\n    def text_response(self) -> Message:\n        message = Message(\n            text=self.input_value,\n        )\n        self.status = self.input_value\n        return message\n"
              },
              "input_value": {
                "_input_type": "MultilineInput",
                "advanced": false,
                "copy_field": false,
                "display_name": "Inputs",
                "dynamic": false,
                "info": "Text to be passed as output.",
                "input_types": [
                  "Message"
                ],
                "list": false,
                "list_add_label": "Add More",
                "load_from_db": false,
                "multiline": true,
                "name": "input_value",
                "placeholder": "",
                "required": false,
                "show": true,
                "title_case": false,
                "tool_mode": false,
                "trace_as_input": true,
                "trace_as_metadata": true,
                "type": "str",
                "value": ""
              }
            },
            "tool_mode": false
          },
          "showNode": true,
          "type": "TextOutput"
        },
        "dragging": false,
        "id": "TextOutput-REnHF",
        "measured": {
          "height": 201,
          "width": 320
        },
        "position": {
          "x": 1836.1521726382523,
          "y": 862.3969389444641
        },
        "selected": false,
        "type": "genericNode"
      }
    ],
    "viewport": {
      "x": -1972.3320544304802,
      "y": 357.5004711143716,
      "zoom": 0.3585615054974626
    }
  },
  "description": "Interactive Language Weaving.",
  "endpoint_name": null,
  "id": "94786ee6-d766-4e06-9ac1-4b321f845cf4",
  "is_component": false,
  "last_tested_version": "1.5.0",
  "name": "Untitled document",
  "tags": []
}